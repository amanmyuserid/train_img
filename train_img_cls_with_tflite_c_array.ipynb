{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d465b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip sequence_img_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f91d8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-30 10:28:57.202283: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-30 10:28:59.496954: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-06-30 10:28:59.496973: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-06-30 10:29:04.899732: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-30 10:29:04.899849: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-30 10:29:04.899857: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version :  2.11.0\n",
      "Tensorflow Lite Version :  2.11.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tflite_runtime\n",
    "\n",
    "print(\"Tensorflow Version : \", tf.__version__)\n",
    "print(\"Tensorflow Lite Version : \", tflite_runtime.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5513bc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D,Dense,Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, ZeroPadding2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "\n",
    "import numpy as np\n",
    "# !pip install numpy==1.20\n",
    "import matplotlib.pyplot as plt\n",
    "# !pip install autokeras\n",
    "# import autokeras as ak\n",
    "import glob\n",
    "import os, cv2\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import MobileNetV3Small\n",
    "from tensorflow.keras.applications import MobileNetV3Large\n",
    "\n",
    "from skimage.util import random_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90e79ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75e7d0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BATCH_SIZE=16\n",
    "\n",
    "IMAGE_SIZE_WIDTH= 80\n",
    "IMAGE_SIZE_HEIGHT = 60 \n",
    "NUM_CHANNEL = 3                                   \n",
    "\n",
    "IMAGE_SHAPE = (IMAGE_SIZE_HEIGHT, IMAGE_SIZE_WIDTH) #(height, width)\n",
    "MODEL_IMAGE_SHAPE = (IMAGE_SIZE_HEIGHT, IMAGE_SIZE_WIDTH, NUM_CHANNEL) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5526e3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir='/home/glarus/HOOK_PROJECT/DATA_COLLECTION_HOOK/single_img_data_training/train'\n",
    "val_data_dir='/home/glarus/HOOK_PROJECT/DATA_COLLECTION_HOOK/single_img_data_training/val'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9e7b4a",
   "metadata": {},
   "source": [
    "# Generate val data from training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4f3a7744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# val_samples = 60\n",
    "# for folder_name in os.listdir(train_data_dir):\n",
    "#     count = 1\n",
    "#     for img_path in glob.glob(f\"{train_data_dir}/{folder_name}/*\"):\n",
    "#         img_name = img_path.split(\"/\")[-1]\n",
    "#         shutil.move(img_path, f\"{val_data_dir}/{folder_name}/{img_name}\")\n",
    "        \n",
    "#         if count == val_samples:\n",
    "#             break\n",
    "#         count += 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2219fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom preprocessing function\n",
    "def custom_augmentation(image):\n",
    "#     print(image)\n",
    "    image1 = image.copy()\n",
    "    if np.random.rand() < 0.8:\n",
    "        augment_type = np.random.randint(1, 6)\n",
    "        print(augment_type)\n",
    "        if augment_type == 1:\n",
    "            image = tf.keras.preprocessing.image.random_rotation(image, 15)\n",
    "        elif augment_type == 2: \n",
    "            image = tf.keras.preprocessing.image.random_shift(image, 0.15, 0.15)\n",
    "        elif augment_type == 3:\n",
    "            image = tf.keras.preprocessing.image.random_zoom(image, (0.85, 1.15))\n",
    "        elif augment_type == 4:\n",
    "            image = tf.keras.preprocessing.image.random_shear(image, 0.15)\n",
    "        elif augment_type == 5:\n",
    "            image = tf.keras.preprocessing.image.random_brightness(image, (0.9, 1.4))\n",
    "        print(image.shape)\n",
    "        \n",
    "        \n",
    "        cv2.imshow(\"ok\", np.concatenate((image1, image[:,:,::-1]), axis=1).astype(np.uint8))\n",
    "        key = cv2.waitKey(0) & 0xFF\n",
    "#         if  key == ord('Q') or key == ord('q'):\n",
    "#             break\n",
    "#         else:\n",
    "#             pass\n",
    "        \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "63f19077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3508215650071691"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "c29a0b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(1, 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55225990",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3983805e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'custom_augmentation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageDataGenerator\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# from tensorflow.keras.layers.preprocessing.image_preprocessing import HORIZONTAL\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m train_datagen\u001b[38;5;241m=\u001b[39mImageDataGenerator(   preprocessing_function\u001b[38;5;241m=\u001b[39m\u001b[43mcustom_augmentation\u001b[49m  \n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m                                  )\n\u001b[1;32m     13\u001b[0m val_datagen\u001b[38;5;241m=\u001b[39mImageDataGenerator(\u001b[38;5;66;03m#rescale=1./255\u001b[39;00m\n\u001b[1;32m     14\u001b[0m                                )\n\u001b[1;32m     19\u001b[0m train_generator\u001b[38;5;241m=\u001b[39mtrain_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(train_data_dir,\n\u001b[1;32m     20\u001b[0m                                                   target_size\u001b[38;5;241m=\u001b[39mIMAGE_SHAPE, \u001b[38;5;66;03m# accept height and wdith order\u001b[39;00m\n\u001b[1;32m     21\u001b[0m                                                   batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m                                                   \n\u001b[1;32m     25\u001b[0m                                                  )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'custom_augmentation' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# from tensorflow.keras.layers.preprocessing.image_preprocessing import HORIZONTAL\n",
    "\n",
    "train_datagen=ImageDataGenerator(   preprocessing_function=custom_augmentation  \n",
    "\n",
    "                                 )\n",
    "\n",
    "val_datagen=ImageDataGenerator(#rescale=1./255\n",
    "                               )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_generator=train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                  target_size=IMAGE_SHAPE, # accept height and wdith order\n",
    "                                                  batch_size=BATCH_SIZE,\n",
    "#                                                   color_mode=\"grayscale\",\n",
    "                                                  class_mode='sparse',\n",
    "                                                  \n",
    "                                                 )\n",
    "\n",
    "val_generator=val_datagen.flow_from_directory(val_data_dir,\n",
    "                                              target_size=IMAGE_SHAPE,\n",
    "                                              batch_size=BATCH_SIZE,\n",
    "#                                               color_mode=\"grayscale\",\n",
    "                                              class_mode='sparse')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e31030",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c763a517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3170 images belonging to 3 classes.\n",
      "Found 180 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# from tensorflow.keras.layers.preprocessing.image_preprocessing import HORIZONTAL\n",
    "\n",
    "train_datagen=ImageDataGenerator(   rotation_range=15,       # Rotate images randomly up to 20 degrees\n",
    "                                    width_shift_range=0.15,   # Shift the width by a fraction of the total width\n",
    "                                    height_shift_range=0.15,  # Shift the height by a fraction of the total height\n",
    "                                    zoom_range=0.15,# Randomly zoom into images by up to 20%\n",
    "                                    shear_range=0.15, \n",
    "#                                     zca_whitening= True,\n",
    "                                    brightness_range=[0.9, 1.35], \n",
    "                                 )\n",
    "\n",
    "val_datagen=ImageDataGenerator(#rescale=1./255\n",
    "                               )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_generator=train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                  target_size=IMAGE_SHAPE, # accept height and wdith order\n",
    "                                                  batch_size=BATCH_SIZE,\n",
    "#                                                   color_mode=\"grayscale\",\n",
    "                                                  class_mode='sparse',\n",
    "                                                  \n",
    "                                                 )\n",
    "\n",
    "val_generator=val_datagen.flow_from_directory(val_data_dir,\n",
    "                                              target_size=IMAGE_SHAPE,\n",
    "                                              batch_size=BATCH_SIZE,\n",
    "#                                               color_mode=\"grayscale\",\n",
    "                                              class_mode='sparse')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4021b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "850658e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DirectoryIterator to tf.data.Dataset\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: train_generator,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, IMAGE_SIZE_HEIGHT,IMAGE_SIZE_WIDTH, NUM_CHANNEL), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None, ), dtype=tf.float32)\n",
    "    )\n",
    ")\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: val_generator,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, IMAGE_SIZE_HEIGHT,IMAGE_SIZE_WIDTH, NUM_CHANNEL), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None, ), dtype=tf.float32)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "a0e4ac93",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "val_dataset = val_dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54e8616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fff5acb5",
   "metadata": {},
   "source": [
    "# Get all class name according to the model will be trained and class weights if unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd2947c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Names :  ['angle', 'none', 'pipe']\n"
     ]
    }
   ],
   "source": [
    "class_names = list(train_generator.class_indices.keys())\n",
    "NUM_CLASSES = len(class_names)\n",
    "print(\"Class Names : \", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "825cf6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names_instances = {}\n",
    "max_instances = 0\n",
    "for i, folder_path in enumerate(sorted(glob.glob(train_data_dir+\"/*\"))):\n",
    "\n",
    "    class_names_instances[folder_path.split(\"/\")[-1]] = len(os.listdir(folder_path))\n",
    "    if max_instances < len(os.listdir(folder_path)):\n",
    "        max_instances = len(os.listdir(folder_path))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e997197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'angle': 951, 'none': 1081, 'pipe': 1138}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34fce193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : angle\n",
      "1 : none\n",
      "2 : pipe\n",
      " \n",
      "class_weights :  {0: 1.1966351209253419, 1: 1.0527289546716003, 2: 1.0}\n"
     ]
    }
   ],
   "source": [
    "class_weights = {}\n",
    "\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    class_weights[i] = max_instances/class_names_instances[class_name]\n",
    "\n",
    "\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    print(f\"{i} : {class_name}\")\n",
    "    \n",
    "print(\" \")\n",
    "\n",
    "print(\"class_weights : \",class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1281ca53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bf4d5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64e86c84",
   "metadata": {},
   "source": [
    "# Visualize images generated from datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca98d551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "images, labels = next(train_generator)\n",
    "batch_size =5\n",
    "fig, axes = plt.subplots(nrows=1, ncols=batch_size, figsize=(10, 4))\n",
    "\n",
    "for i in range(batch_size):\n",
    "    \n",
    "    # Rescale pixel values to [0, 1]\n",
    "    image = images[i] / 255.0\n",
    "    \n",
    "    axes[i].imshow(image)\n",
    "    axes[i].axis('off')\n",
    "    axes[i].set_title('{}'.format(class_names[int(labels[i])]))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "092da258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "(60, 80, 3)\n",
      "2\n",
      "(60, 80, 3)\n",
      "2\n",
      "(60, 80, 3)\n",
      "5\n",
      "(60, 80, 3)\n",
      "2\n",
      "(60, 80, 3)\n",
      "3\n",
      "(60, 80, 3)\n",
      "4\n",
      "(60, 80, 3)\n",
      "3\n",
      "(60, 80, 3)\n",
      "4\n",
      "(60, 80, 3)\n",
      "1\n",
      "(60, 80, 3)\n",
      "2\n",
      "(60, 80, 3)\n",
      "2\n",
      "(60, 80, 3)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3260773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0f6df0d",
   "metadata": {},
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ca32e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-27 09:42:37.844396: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-06-27 09:42:37.844500: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (glarus-pc): /proc/driver/nvidia/version does not exist\n",
      "2023-06-27 09:42:37.886248: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling (Rescaling)       (None, 120, 160, 3)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 118, 158, 4)       112       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 118, 158, 4)      16        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 59, 79, 4)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 57, 77, 6)         222       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 57, 77, 6)        24        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 28, 38, 6)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 13, 18, 3)         165       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 13, 18, 3)        12        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 9, 3)          0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 162)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 162)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 489       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,040\n",
      "Trainable params: 1,014\n",
      "Non-trainable params: 26\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=MODEL_IMAGE_SHAPE),\n",
    "    tf.keras.layers.Rescaling(1./255), \n",
    "    \n",
    "    tf.keras.layers.Conv2D(filters=4, kernel_size=3, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(filters=6, kernel_size=3, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(filters=3, kernel_size=3, strides=2, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Dense(units=NUM_CLASSES, activation='softmax')\n",
    "])\n",
    "\n",
    "#model.build(input_shape=(None, IMAGE_SIZE_WIDTH, IMAGE_SIZE_HEIGHT, NUM_CHANNEL))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15800233",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5af55448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 118, 158, 4)       112       \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 118, 158, 4)      16        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 116, 156, 6)       222       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 58, 78, 6)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 28, 38, 1)         55        \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 28, 38, 1)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1064)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 3195      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,600\n",
      "Trainable params: 3,592\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.models.Sequential([\n",
    "    # Depthwise convolutional layer\n",
    "    # tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=MODEL_IMAGE_SHAPE),\n",
    "    #tf.keras.layers.Rescaling(1./255), \n",
    "    tf.keras.layers.Conv2D(filters=4, kernel_size=3, activation='relu', input_shape=MODEL_IMAGE_SHAPE),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(filters=6, kernel_size=3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters=1, kernel_size=3, strides=2, activation='relu'),\n",
    "    # Dropout layer\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    # Flatten layer\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # Dense layers\n",
    "    # tf.keras.layers.Dense(units=8, activation='relu'),\n",
    "    # tf.keras.layers.Dropout(0.5),\n",
    "    # Output layer\n",
    "    tf.keras.layers.Dense(units=NUM_CLASSES, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c44d55",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "361e44d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 45, 240, 3)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 23, 120, 1)   27          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 23, 120, 1)   4           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (ReLU)               (None, 23, 120, 1)   0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_conv (Depthwi (None, 23, 120, 1)   9           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block_1_dw_bn (BatchNormalizati (None, 23, 120, 1)   4           block_1_depthwise_conv[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_1_dw_relu (ReLU)          (None, 23, 120, 1)   0           block_1_dw_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1_compress (Conv2D)       (None, 23, 120, 4)   4           block_1_dw_relu[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1_compress_bn (BatchNorma (None, 23, 120, 4)   16          block_1_compress[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand (Conv2D)         (None, 23, 120, 4)   16          block_1_compress_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_bn (BatchNormali (None, 23, 120, 4)   16          block_2_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_relu (ReLU)      (None, 23, 120, 4)   0           block_2_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_conv (Depthwi (None, 12, 60, 4)    36          block_2_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_2_dw_bn (BatchNormalizati (None, 12, 60, 4)    16          block_2_depthwise_conv[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_2_dw_relu (ReLU)          (None, 12, 60, 4)    0           block_2_dw_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2_compress (Conv2D)       (None, 12, 60, 6)    24          block_2_dw_relu[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_compress_bn (BatchNorma (None, 12, 60, 6)    24          block_2_compress[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand (Conv2D)         (None, 12, 60, 6)    36          block_2_compress_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_bn (BatchNormali (None, 12, 60, 6)    24          block_3_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_relu (ReLU)      (None, 12, 60, 6)    0           block_3_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_conv (Depthwi (None, 12, 60, 6)    54          block_3_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_3_dw_bn (BatchNormalizati (None, 12, 60, 6)    24          block_3_depthwise_conv[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_3_dw_relu (ReLU)          (None, 12, 60, 6)    0           block_3_dw_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3_compress (Conv2D)       (None, 12, 60, 6)    36          block_3_dw_relu[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3_compress_bn (BatchNorma (None, 12, 60, 6)    24          block_3_compress[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 12, 60, 6)    0           block_2_compress_bn[0][0]        \n",
      "                                                                 block_3_compress_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "last_conv (Conv2D)              (None, 8, 56, 1)     150         add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "last_bn (BatchNormalization)    (None, 8, 56, 1)     4           last_conv[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "last_relu (ReLU)                (None, 8, 56, 1)     0           last_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 448)          0           last_relu[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 4)            1796        flatten_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,344\n",
      "Trainable params: 2,266\n",
      "Non-trainable params: 78\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/Haikoitoh/paper-implementation/blob/main/MobileNetV2.ipynb\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, DepthwiseConv2D, ReLU, BatchNormalization, add,Softmax, AveragePooling2D, Dense, Input, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def expansion_block(x,t,filters,block_id):\n",
    "    prefix = 'block_{}_'.format(block_id)\n",
    "    total_filters = t*filters\n",
    "    x = Conv2D(total_filters,1,padding='same',use_bias=False, name = prefix +'expand')(x)\n",
    "    x = BatchNormalization(name=prefix +'expand_bn')(x)\n",
    "    x = ReLU(6,name = prefix +'expand_relu')(x)\n",
    "    return x\n",
    "\n",
    "def depthwise_block(x,stride,block_id):\n",
    "    prefix = 'block_{}_'.format(block_id)\n",
    "    x = DepthwiseConv2D(3,strides=(stride,stride),padding ='same', use_bias = False, name = prefix + 'depthwise_conv')(x)\n",
    "    x = BatchNormalization(name=prefix +'dw_bn')(x)\n",
    "    x = ReLU(6,name=prefix +'dw_relu')(x)\n",
    "    return x\n",
    "\n",
    "def projection_block(x,out_channels,block_id):\n",
    "    prefix = 'block_{}_'.format(block_id)\n",
    "    x = Conv2D(filters = out_channels,kernel_size = 1,padding='same',use_bias=False,name= prefix + 'compress')(x)\n",
    "    x = BatchNormalization(name=prefix +'compress_bn')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def Bottleneck(x,t,filters, out_channels,stride,block_id):\n",
    "    y = expansion_block(x,t,filters,block_id)\n",
    "    y = depthwise_block(y,stride,block_id)\n",
    "    y = projection_block(y, out_channels,block_id)\n",
    "    if y.shape[-1]==x.shape[-1]:\n",
    "        y = add([x,y])\n",
    "    return y\n",
    "\n",
    "\n",
    "def MobileNetV2(input_image = (224,224,3), n_classes=1000):\n",
    "    input = Input(input_image)\n",
    "\n",
    "    # x1 = tf.keras.layers.AveragePooling2D(pool_size=(5, 5), strides=3)(input)\n",
    "    # x2 = tf.keras.layers.MaxPooling2D(pool_size=(5, 5), strides=3)(input)\n",
    "    # x = tf.keras.layers.Concatenate()([x1, x2])    \n",
    "\n",
    "    x = Conv2D(1,kernel_size=3,strides=(2, 2),padding = 'same', use_bias=False)(input)\n",
    "    x = BatchNormalization(name='conv1_bn')(x)\n",
    "    x = ReLU(6, name = 'conv1_relu')(x)\n",
    "\n",
    "    # 17 Bottlenecks\n",
    "\n",
    "    x = depthwise_block(x,stride=1,block_id=1)\n",
    "    x = projection_block(x, out_channels=4,block_id=1)\n",
    "\n",
    "    x = Bottleneck(x, t = 1, filters = x.shape[-1], out_channels = 6, stride = 2,block_id = 2)\n",
    "    x = Bottleneck(x, t = 1, filters = x.shape[-1], out_channels = 6, stride = 1,block_id = 3)\n",
    "\n",
    "    # x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 32, stride = 2,block_id = 4)\n",
    "    # x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 32, stride = 1,block_id = 5)\n",
    "    # x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 32, stride = 1,block_id = 6)\n",
    "\n",
    "    # x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 64, stride = 2,block_id = 7)\n",
    "    # x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 64, stride = 1,block_id = 8)\n",
    "    # x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 64, stride = 1,block_id = 9)\n",
    "    # x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 64, stride = 1,block_id = 10)\n",
    "\n",
    "    # x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 96, stride = 1,block_id = 11)\n",
    "    # x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 96, stride = 1,block_id = 12)\n",
    "    # x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 96, stride = 1,block_id = 13)\n",
    "\n",
    "    # x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 160, stride = 2,block_id = 14)\n",
    "    # x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 160, stride = 1,block_id = 15)\n",
    "    # x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 160, stride = 1,block_id = 16)\n",
    "\n",
    "    # x = Bottleneck(x, t = 2, filters = x.shape[-1], out_channels = 8, stride = 1,block_id = 17)\n",
    "\n",
    "\n",
    "    #1*1 conv\n",
    "    x = Conv2D(filters = 1,kernel_size = 5,padding='valid',use_bias=False, name = 'last_conv')(x)\n",
    "    x = BatchNormalization(name='last_bn')(x)\n",
    "    x = ReLU(6,name='last_relu')(x)\n",
    "\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    \n",
    "\n",
    "\n",
    "    output = Dense(n_classes,activation='softmax')(x)\n",
    "\n",
    "    model = Model(input, output)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = MobileNetV2(MODEL_IMAGE_SHAPE, NUM_CLASSES)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42409fe",
   "metadata": {},
   "source": [
    "# Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "7ce11ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_40 (InputLayer)        [(None, 45, 180, 3)]      0         \n",
      "_________________________________________________________________\n",
      "conv2d_91 (Conv2D)           (None, 15, 60, 2)         56        \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 15, 60, 2)         8         \n",
      "_________________________________________________________________\n",
      "re_lu_28 (ReLU)              (None, 15, 60, 2)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_92 (Conv2D)           (None, 5, 20, 2)          38        \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 5, 20, 2)          8         \n",
      "_________________________________________________________________\n",
      "re_lu_29 (ReLU)              (None, 5, 20, 2)          0         \n",
      "_________________________________________________________________\n",
      "flatten_39 (Flatten)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 4)                 804       \n",
      "=================================================================\n",
      "Total params: 914\n",
      "Trainable params: 906\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/Haikoitoh/paper-implementation/blob/main/MobileNetV2.ipynb\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, DepthwiseConv2D, ReLU, BatchNormalization, add,Softmax, AveragePooling2D, Dense, Input, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def expansion_block(x,t,filters,block_id):\n",
    "    prefix = 'block_{}_'.format(block_id)\n",
    "    total_filters = t*filters\n",
    "    x = Conv2D(total_filters,1,padding='same',use_bias=False, name = prefix +'expand')(x)\n",
    "    x = BatchNormalization(name=prefix +'expand_bn')(x)\n",
    "    x = ReLU(6,name = prefix +'expand_relu')(x)\n",
    "    return x\n",
    "\n",
    "def depthwise_block(x,stride,block_id):\n",
    "    prefix = 'block_{}_'.format(block_id)\n",
    "    x = DepthwiseConv2D(3,strides=(stride,stride),padding ='same', use_bias = False, name = prefix + 'depthwise_conv')(x)\n",
    "    x = BatchNormalization(name=prefix +'dw_bn')(x)\n",
    "    x = ReLU(6,name=prefix +'dw_relu')(x)\n",
    "    return x\n",
    "\n",
    "def projection_block(x,out_channels,block_id):\n",
    "    prefix = 'block_{}_'.format(block_id)\n",
    "    x = Conv2D(filters = out_channels,kernel_size = 1,padding='same',use_bias=False,name= prefix + 'compress')(x)\n",
    "    x = BatchNormalization(name=prefix +'compress_bn')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def Bottleneck(x,t,filters, out_channels,stride,block_id):\n",
    "    y = expansion_block(x,t,filters,block_id)\n",
    "    y = depthwise_block(y,stride,block_id)\n",
    "    y = projection_block(y, out_channels,block_id)\n",
    "    if y.shape[-1]==x.shape[-1]:\n",
    "        y = add([x,y])\n",
    "    return y\n",
    "\n",
    "\n",
    "def MobileNetV2(input_image = (224,224,3), n_classes=1000):\n",
    "    input = Input(input_image)\n",
    "\n",
    "    x = Conv2D(2,kernel_size=(3, 3),strides=(3, 3),padding = 'valid', use_bias=True)(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU(6)(x)\n",
    "    \n",
    "    x = Conv2D(2,kernel_size=(3, 3),strides=(3, 3),padding = 'valid', use_bias=True)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU(6)(x)\n",
    "    \n",
    "#     x = Conv2D(1,kernel_size=(3, 3),strides=(3, 3),padding = 'valid', use_bias=True)(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = ReLU(6)(x)\n",
    "    \n",
    "#     x = Conv2D(1,kernel_size=(3, 3),strides=(3, 3),padding = 'valid', use_bias=True)(x)\n",
    "#     x = BatchNormalization(name='conv3_bn')(x)\n",
    "#     x = ReLU(6, name = 'conv3_relu')(x)\n",
    "    \n",
    "#     x = Conv2D(1,kernel_size=(5, 5),strides=(3, 3),padding = 'valid', use_bias=False)(x)\n",
    "#     x = BatchNormalization(name='conv3_bn')(x)\n",
    "#     x = ReLU(6, name = 'conv3_relu')(x)\n",
    "    \n",
    "#     x = Conv2D(1,kernel_size=(3, 3),strides=(2, 2),padding = 'valid', use_bias=False)(x)\n",
    "#     x = BatchNormalization(name='conv3_bn')(x)\n",
    "#     x = ReLU(6, name = 'conv3_relu')(x)\n",
    "\n",
    "#     x = depthwise_block(x,stride=1,block_id=1)\n",
    "#     x = projection_block(x, out_channels=4,block_id=1)\n",
    "\n",
    "#     x = Bottleneck(x, t = 1, filters = x.shape[-1], out_channels = 6, stride = 2,block_id = 2)\n",
    "#     x = Bottleneck(x, t = 1, filters = x.shape[-1], out_channels = 6, stride = 1,block_id = 3)\n",
    "\n",
    "#     x = Conv2D(filters = 1,kernel_size = 5,padding='valid',use_bias=False, name = 'last_conv')(x)\n",
    "#     x = BatchNormalization(name='last_bn')(x)\n",
    "#     x = ReLU(6,name='last_relu')(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    output = Dense(n_classes,activation='softmax', use_bias=True)(x)\n",
    "\n",
    "    model = Model(input, output)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = MobileNetV2(MODEL_IMAGE_SHAPE, NUM_CLASSES)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca7669f",
   "metadata": {},
   "source": [
    "# mobile net v3 small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "71afc41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MobilenetV3small\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_13 (InputLayer)          [(None, 60, 80, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " rescaling_4 (Rescaling)        (None, 60, 80, 3)    0           ['input_13[0][0]']               \n",
      "                                                                                                  \n",
      " Conv (Conv2D)                  (None, 30, 40, 16)   432         ['rescaling_4[0][0]']            \n",
      "                                                                                                  \n",
      " Conv/BatchNorm (BatchNormaliza  (None, 30, 40, 16)  64          ['Conv[0][0]']                   \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " re_lu_75 (ReLU)                (None, 30, 40, 16)   0           ['Conv/BatchNorm[0][0]']         \n",
      "                                                                                                  \n",
      " expanded_conv/depthwise/pad (Z  (None, 31, 41, 16)  0           ['re_lu_75[0][0]']               \n",
      " eroPadding2D)                                                                                    \n",
      "                                                                                                  \n",
      " expanded_conv/depthwise (Depth  (None, 15, 20, 16)  144         ['expanded_conv/depthwise/pad[0][\n",
      " wiseConv2D)                                                     0]']                             \n",
      "                                                                                                  \n",
      " expanded_conv/depthwise/BatchN  (None, 15, 20, 16)  64          ['expanded_conv/depthwise[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " re_lu_76 (ReLU)                (None, 15, 20, 16)   0           ['expanded_conv/depthwise/BatchNo\n",
      "                                                                 rm[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv/project (Conv2D)  (None, 15, 20, 8)   128         ['re_lu_76[0][0]']               \n",
      "                                                                                                  \n",
      " expanded_conv/project/BatchNor  (None, 15, 20, 8)   32          ['expanded_conv/project[0][0]']  \n",
      " m (BatchNormalization)                                                                           \n",
      "                                                                                                  \n",
      " expanded_conv_1/expand (Conv2D  (None, 15, 20, 40)  320         ['expanded_conv/project/BatchNorm\n",
      " )                                                               [0][0]']                         \n",
      "                                                                                                  \n",
      " expanded_conv_1/expand/BatchNo  (None, 15, 20, 40)  160         ['expanded_conv_1/expand[0][0]'] \n",
      " rm (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " re_lu_77 (ReLU)                (None, 15, 20, 40)   0           ['expanded_conv_1/expand/BatchNor\n",
      "                                                                 m[0][0]']                        \n",
      "                                                                                                  \n",
      " expanded_conv_1/depthwise/pad   (None, 17, 21, 40)  0           ['re_lu_77[0][0]']               \n",
      " (ZeroPadding2D)                                                                                  \n",
      "                                                                                                  \n",
      " expanded_conv_1/depthwise (Dep  (None, 8, 10, 40)   360         ['expanded_conv_1/depthwise/pad[0\n",
      " thwiseConv2D)                                                   ][0]']                           \n",
      "                                                                                                  \n",
      " expanded_conv_1/depthwise/Batc  (None, 8, 10, 40)   160         ['expanded_conv_1/depthwise[0][0]\n",
      " hNorm (BatchNormalization)                                      ']                               \n",
      "                                                                                                  \n",
      " re_lu_78 (ReLU)                (None, 8, 10, 40)    0           ['expanded_conv_1/depthwise/Batch\n",
      "                                                                 Norm[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_1/project (Conv2  (None, 8, 10, 8)    320         ['re_lu_78[0][0]']               \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_1/project/BatchN  (None, 8, 10, 8)    32          ['expanded_conv_1/project[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " expanded_conv_2/expand (Conv2D  (None, 8, 10, 32)   256         ['expanded_conv_1/project/BatchNo\n",
      " )                                                               rm[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv_2/expand/BatchNo  (None, 8, 10, 32)   128         ['expanded_conv_2/expand[0][0]'] \n",
      " rm (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " re_lu_79 (ReLU)                (None, 8, 10, 32)    0           ['expanded_conv_2/expand/BatchNor\n",
      "                                                                 m[0][0]']                        \n",
      "                                                                                                  \n",
      " expanded_conv_2/depthwise (Dep  (None, 8, 10, 32)   288         ['re_lu_79[0][0]']               \n",
      " thwiseConv2D)                                                                                    \n",
      "                                                                                                  \n",
      " expanded_conv_2/depthwise/Batc  (None, 8, 10, 32)   128         ['expanded_conv_2/depthwise[0][0]\n",
      " hNorm (BatchNormalization)                                      ']                               \n",
      "                                                                                                  \n",
      " re_lu_80 (ReLU)                (None, 8, 10, 32)    0           ['expanded_conv_2/depthwise/Batch\n",
      "                                                                 Norm[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_2/project (Conv2  (None, 8, 10, 8)    256         ['re_lu_80[0][0]']               \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_2/project/BatchN  (None, 8, 10, 8)    32          ['expanded_conv_2/project[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " expanded_conv_2/Add (Add)      (None, 8, 10, 8)     0           ['expanded_conv_1/project/BatchNo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 rm[0][0]',                       \n",
      "                                                                  'expanded_conv_2/project/BatchNo\n",
      "                                                                 rm[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv_3/expand (Conv2D  (None, 8, 10, 32)   256         ['expanded_conv_2/Add[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv_3/expand/BatchNo  (None, 8, 10, 32)   128         ['expanded_conv_3/expand[0][0]'] \n",
      " rm (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " re_lu_81 (ReLU)                (None, 8, 10, 32)    0           ['expanded_conv_3/expand/BatchNor\n",
      "                                                                 m[0][0]']                        \n",
      "                                                                                                  \n",
      " expanded_conv_3/depthwise/pad   (None, 9, 11, 32)   0           ['re_lu_81[0][0]']               \n",
      " (ZeroPadding2D)                                                                                  \n",
      "                                                                                                  \n",
      " expanded_conv_3/depthwise (Dep  (None, 4, 5, 32)    288         ['expanded_conv_3/depthwise/pad[0\n",
      " thwiseConv2D)                                                   ][0]']                           \n",
      "                                                                                                  \n",
      " expanded_conv_3/depthwise/Batc  (None, 4, 5, 32)    128         ['expanded_conv_3/depthwise[0][0]\n",
      " hNorm (BatchNormalization)                                      ']                               \n",
      "                                                                                                  \n",
      " re_lu_82 (ReLU)                (None, 4, 5, 32)     0           ['expanded_conv_3/depthwise/Batch\n",
      "                                                                 Norm[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_3/project (Conv2  (None, 4, 5, 8)     256         ['re_lu_82[0][0]']               \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_3/project/BatchN  (None, 4, 5, 8)     32          ['expanded_conv_3/project[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " expanded_conv_4/expand (Conv2D  (None, 4, 5, 48)    384         ['expanded_conv_3/project/BatchNo\n",
      " )                                                               rm[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv_4/expand/BatchNo  (None, 4, 5, 48)    192         ['expanded_conv_4/expand[0][0]'] \n",
      " rm (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " re_lu_83 (ReLU)                (None, 4, 5, 48)     0           ['expanded_conv_4/expand/BatchNor\n",
      "                                                                 m[0][0]']                        \n",
      "                                                                                                  \n",
      " expanded_conv_4/depthwise (Dep  (None, 4, 5, 48)    432         ['re_lu_83[0][0]']               \n",
      " thwiseConv2D)                                                                                    \n",
      "                                                                                                  \n",
      " expanded_conv_4/depthwise/Batc  (None, 4, 5, 48)    192         ['expanded_conv_4/depthwise[0][0]\n",
      " hNorm (BatchNormalization)                                      ']                               \n",
      "                                                                                                  \n",
      " re_lu_84 (ReLU)                (None, 4, 5, 48)     0           ['expanded_conv_4/depthwise/Batch\n",
      "                                                                 Norm[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_4/project (Conv2  (None, 4, 5, 8)     384         ['re_lu_84[0][0]']               \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_4/project/BatchN  (None, 4, 5, 8)     32          ['expanded_conv_4/project[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " expanded_conv_4/Add (Add)      (None, 4, 5, 8)      0           ['expanded_conv_3/project/BatchNo\n",
      "                                                                 rm[0][0]',                       \n",
      "                                                                  'expanded_conv_4/project/BatchNo\n",
      "                                                                 rm[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv_5/expand (Conv2D  (None, 4, 5, 48)    384         ['expanded_conv_4/Add[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv_5/expand/BatchNo  (None, 4, 5, 48)    192         ['expanded_conv_5/expand[0][0]'] \n",
      " rm (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " re_lu_85 (ReLU)                (None, 4, 5, 48)     0           ['expanded_conv_5/expand/BatchNor\n",
      "                                                                 m[0][0]']                        \n",
      "                                                                                                  \n",
      " expanded_conv_5/depthwise (Dep  (None, 4, 5, 48)    432         ['re_lu_85[0][0]']               \n",
      " thwiseConv2D)                                                                                    \n",
      "                                                                                                  \n",
      " expanded_conv_5/depthwise/Batc  (None, 4, 5, 48)    192         ['expanded_conv_5/depthwise[0][0]\n",
      " hNorm (BatchNormalization)                                      ']                               \n",
      "                                                                                                  \n",
      " re_lu_86 (ReLU)                (None, 4, 5, 48)     0           ['expanded_conv_5/depthwise/Batch\n",
      "                                                                 Norm[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_5/project (Conv2  (None, 4, 5, 8)     384         ['re_lu_86[0][0]']               \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_5/project/BatchN  (None, 4, 5, 8)     32          ['expanded_conv_5/project[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " expanded_conv_5/Add (Add)      (None, 4, 5, 8)      0           ['expanded_conv_4/Add[0][0]',    \n",
      "                                                                  'expanded_conv_5/project/BatchNo\n",
      "                                                                 rm[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv_6/expand (Conv2D  (None, 4, 5, 24)    192         ['expanded_conv_5/Add[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv_6/expand/BatchNo  (None, 4, 5, 24)    96          ['expanded_conv_6/expand[0][0]'] \n",
      " rm (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " re_lu_87 (ReLU)                (None, 4, 5, 24)     0           ['expanded_conv_6/expand/BatchNor\n",
      "                                                                 m[0][0]']                        \n",
      "                                                                                                  \n",
      " expanded_conv_6/depthwise (Dep  (None, 4, 5, 24)    216         ['re_lu_87[0][0]']               \n",
      " thwiseConv2D)                                                                                    \n",
      "                                                                                                  \n",
      " expanded_conv_6/depthwise/Batc  (None, 4, 5, 24)    96          ['expanded_conv_6/depthwise[0][0]\n",
      " hNorm (BatchNormalization)                                      ']                               \n",
      "                                                                                                  \n",
      " re_lu_88 (ReLU)                (None, 4, 5, 24)     0           ['expanded_conv_6/depthwise/Batch\n",
      "                                                                 Norm[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_6/project (Conv2  (None, 4, 5, 8)     192         ['re_lu_88[0][0]']               \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_6/project/BatchN  (None, 4, 5, 8)     32          ['expanded_conv_6/project[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " expanded_conv_6/Add (Add)      (None, 4, 5, 8)      0           ['expanded_conv_5/Add[0][0]',    \n",
      "                                                                  'expanded_conv_6/project/BatchNo\n",
      "                                                                 rm[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv_7/expand (Conv2D  (None, 4, 5, 24)    192         ['expanded_conv_6/Add[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv_7/expand/BatchNo  (None, 4, 5, 24)    96          ['expanded_conv_7/expand[0][0]'] \n",
      " rm (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " re_lu_89 (ReLU)                (None, 4, 5, 24)     0           ['expanded_conv_7/expand/BatchNor\n",
      "                                                                 m[0][0]']                        \n",
      "                                                                                                  \n",
      " expanded_conv_7/depthwise (Dep  (None, 4, 5, 24)    216         ['re_lu_89[0][0]']               \n",
      " thwiseConv2D)                                                                                    \n",
      "                                                                                                  \n",
      " expanded_conv_7/depthwise/Batc  (None, 4, 5, 24)    96          ['expanded_conv_7/depthwise[0][0]\n",
      " hNorm (BatchNormalization)                                      ']                               \n",
      "                                                                                                  \n",
      " re_lu_90 (ReLU)                (None, 4, 5, 24)     0           ['expanded_conv_7/depthwise/Batch\n",
      "                                                                 Norm[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_7/project (Conv2  (None, 4, 5, 8)     192         ['re_lu_90[0][0]']               \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_7/project/BatchN  (None, 4, 5, 8)     32          ['expanded_conv_7/project[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " expanded_conv_7/Add (Add)      (None, 4, 5, 8)      0           ['expanded_conv_6/Add[0][0]',    \n",
      "                                                                  'expanded_conv_7/project/BatchNo\n",
      "                                                                 rm[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv_8/expand (Conv2D  (None, 4, 5, 48)    384         ['expanded_conv_7/Add[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv_8/expand/BatchNo  (None, 4, 5, 48)    192         ['expanded_conv_8/expand[0][0]'] \n",
      " rm (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " re_lu_91 (ReLU)                (None, 4, 5, 48)     0           ['expanded_conv_8/expand/BatchNor\n",
      "                                                                 m[0][0]']                        \n",
      "                                                                                                  \n",
      " expanded_conv_8/depthwise/pad   (None, 5, 7, 48)    0           ['re_lu_91[0][0]']               \n",
      " (ZeroPadding2D)                                                                                  \n",
      "                                                                                                  \n",
      " expanded_conv_8/depthwise (Dep  (None, 2, 3, 48)    432         ['expanded_conv_8/depthwise/pad[0\n",
      " thwiseConv2D)                                                   ][0]']                           \n",
      "                                                                                                  \n",
      " expanded_conv_8/depthwise/Batc  (None, 2, 3, 48)    192         ['expanded_conv_8/depthwise[0][0]\n",
      " hNorm (BatchNormalization)                                      ']                               \n",
      "                                                                                                  \n",
      " re_lu_92 (ReLU)                (None, 2, 3, 48)     0           ['expanded_conv_8/depthwise/Batch\n",
      "                                                                 Norm[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_8/project (Conv2  (None, 2, 3, 8)     384         ['re_lu_92[0][0]']               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_8/project/BatchN  (None, 2, 3, 8)     32          ['expanded_conv_8/project[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " expanded_conv_9/expand (Conv2D  (None, 2, 3, 48)    384         ['expanded_conv_8/project/BatchNo\n",
      " )                                                               rm[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv_9/expand/BatchNo  (None, 2, 3, 48)    192         ['expanded_conv_9/expand[0][0]'] \n",
      " rm (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " re_lu_93 (ReLU)                (None, 2, 3, 48)     0           ['expanded_conv_9/expand/BatchNor\n",
      "                                                                 m[0][0]']                        \n",
      "                                                                                                  \n",
      " expanded_conv_9/depthwise (Dep  (None, 2, 3, 48)    432         ['re_lu_93[0][0]']               \n",
      " thwiseConv2D)                                                                                    \n",
      "                                                                                                  \n",
      " expanded_conv_9/depthwise/Batc  (None, 2, 3, 48)    192         ['expanded_conv_9/depthwise[0][0]\n",
      " hNorm (BatchNormalization)                                      ']                               \n",
      "                                                                                                  \n",
      " re_lu_94 (ReLU)                (None, 2, 3, 48)     0           ['expanded_conv_9/depthwise/Batch\n",
      "                                                                 Norm[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_9/project (Conv2  (None, 2, 3, 8)     384         ['re_lu_94[0][0]']               \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_9/project/BatchN  (None, 2, 3, 8)     32          ['expanded_conv_9/project[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " expanded_conv_9/Add (Add)      (None, 2, 3, 8)      0           ['expanded_conv_8/project/BatchNo\n",
      "                                                                 rm[0][0]',                       \n",
      "                                                                  'expanded_conv_9/project/BatchNo\n",
      "                                                                 rm[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv_10/expand (Conv2  (None, 2, 3, 48)    384         ['expanded_conv_9/Add[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_10/expand/BatchN  (None, 2, 3, 48)    192         ['expanded_conv_10/expand[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " re_lu_95 (ReLU)                (None, 2, 3, 48)     0           ['expanded_conv_10/expand/BatchNo\n",
      "                                                                 rm[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv_10/depthwise (De  (None, 2, 3, 48)    432         ['re_lu_95[0][0]']               \n",
      " pthwiseConv2D)                                                                                   \n",
      "                                                                                                  \n",
      " expanded_conv_10/depthwise/Bat  (None, 2, 3, 48)    192         ['expanded_conv_10/depthwise[0][0\n",
      " chNorm (BatchNormalization)                                     ]']                              \n",
      "                                                                                                  \n",
      " re_lu_96 (ReLU)                (None, 2, 3, 48)     0           ['expanded_conv_10/depthwise/Batc\n",
      "                                                                 hNorm[0][0]']                    \n",
      "                                                                                                  \n",
      " expanded_conv_10/project (Conv  (None, 2, 3, 8)     384         ['re_lu_96[0][0]']               \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " expanded_conv_10/project/Batch  (None, 2, 3, 8)     32          ['expanded_conv_10/project[0][0]'\n",
      " Norm (BatchNormalization)                                       ]                                \n",
      "                                                                                                  \n",
      " expanded_conv_10/Add (Add)     (None, 2, 3, 8)      0           ['expanded_conv_9/Add[0][0]',    \n",
      "                                                                  'expanded_conv_10/project/BatchN\n",
      "                                                                 orm[0][0]']                      \n",
      "                                                                                                  \n",
      " Conv_1 (Conv2D)                (None, 2, 3, 48)     384         ['expanded_conv_10/Add[0][0]']   \n",
      "                                                                                                  \n",
      " Conv_1/BatchNorm (BatchNormali  (None, 2, 3, 48)    192         ['Conv_1[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " re_lu_97 (ReLU)                (None, 2, 3, 48)     0           ['Conv_1/BatchNorm[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 14,696\n",
      "Trainable params: 12,792\n",
      "Non-trainable params: 1,904\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " MobilenetV3small (Functiona  (None, 2, 3, 48)         14696     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 288)               0         \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 288)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 3)                 867       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,563\n",
      "Trainable params: 13,659\n",
      "Non-trainable params: 1,904\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "num_classes = 3\n",
    "\n",
    "base_model = MobileNetV3Small(\n",
    "                                input_shape=MODEL_IMAGE_SHAPE,\n",
    "                                alpha=0.01,\n",
    "                                dropout_rate=0.2,\n",
    "                                minimalistic=True, # if True, aims to provide a lightweight and efficient model for image classification tasks with minimal computational resources.\n",
    "                                 \n",
    "                                include_top=False,\n",
    "                                weights=None , #'imagenet' , None\n",
    "                                \n",
    "                             )\n",
    "base_model.trainable = True\n",
    "\n",
    "print(base_model.summary())\n",
    "\n",
    "model = keras.Sequential([\n",
    "    base_model,\n",
    "#     layers.GlobalAveragePooling2D(),\n",
    "    layers.Flatten(),\n",
    "#     layers.Dense(16, activation='relu'),\n",
    "#     layers.BatchNormalization(),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b80da706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MobilenetV3small\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 60, 80, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " rescaling_1 (Rescaling)        (None, 60, 80, 3)    0           ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " Conv (Conv2D)                  (None, 30, 40, 16)   432         ['rescaling_1[0][0]']            \n",
      "                                                                                                  \n",
      " Conv/BatchNorm (BatchNormaliza  (None, 30, 40, 16)  64          ['Conv[0][0]']                   \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_28 (TFOpL  (None, 30, 40, 16)  0           ['Conv/BatchNorm[0][0]']         \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " re_lu_39 (ReLU)                (None, 30, 40, 16)   0           ['tf.__operators__.add_28[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_28 (TFOpLambd  (None, 30, 40, 16)  0           ['re_lu_39[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " multiply_20 (Multiply)         (None, 30, 40, 16)   0           ['Conv/BatchNorm[0][0]',         \n",
      "                                                                  'tf.math.multiply_28[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv/depthwise/pad (Z  (None, 31, 41, 16)  0           ['multiply_20[0][0]']            \n",
      " eroPadding2D)                                                                                    \n",
      "                                                                                                  \n",
      " expanded_conv/depthwise (Depth  (None, 15, 20, 16)  144         ['expanded_conv/depthwise/pad[0][\n",
      " wiseConv2D)                                                     0]']                             \n",
      "                                                                                                  \n",
      " expanded_conv/depthwise/BatchN  (None, 15, 20, 16)  64          ['expanded_conv/depthwise[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " re_lu_40 (ReLU)                (None, 15, 20, 16)   0           ['expanded_conv/depthwise/BatchNo\n",
      "                                                                 rm[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv/squeeze_excite/A  (None, 1, 1, 16)    0           ['re_lu_40[0][0]']               \n",
      " vgPool (GlobalAveragePooling2D                                                                   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv/squeeze_excite/C  (None, 1, 1, 8)     136         ['expanded_conv/squeeze_excite/Av\n",
      " onv (Conv2D)                                                    gPool[0][0]']                    \n",
      "                                                                                                  \n",
      " expanded_conv/squeeze_excite/R  (None, 1, 1, 8)     0           ['expanded_conv/squeeze_excite/Co\n",
      " elu (ReLU)                                                      nv[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv/squeeze_excite/C  (None, 1, 1, 16)    144         ['expanded_conv/squeeze_excite/Re\n",
      " onv_1 (Conv2D)                                                  lu[0][0]']                       \n",
      "                                                                                                  \n",
      " tf.__operators__.add_29 (TFOpL  (None, 1, 1, 16)    0           ['expanded_conv/squeeze_excite/Co\n",
      " ambda)                                                          nv_1[0][0]']                     \n",
      "                                                                                                  \n",
      " re_lu_41 (ReLU)                (None, 1, 1, 16)     0           ['tf.__operators__.add_29[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_29 (TFOpLambd  (None, 1, 1, 16)    0           ['re_lu_41[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv/squeeze_excite/M  (None, 15, 20, 16)  0           ['re_lu_40[0][0]',               \n",
      " ul (Multiply)                                                    'tf.math.multiply_29[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv/project (Conv2D)  (None, 15, 20, 8)   128         ['expanded_conv/squeeze_excite/Mu\n",
      "                                                                 l[0][0]']                        \n",
      "                                                                                                  \n",
      " expanded_conv/project/BatchNor  (None, 15, 20, 8)   32          ['expanded_conv/project[0][0]']  \n",
      " m (BatchNormalization)                                                                           \n",
      "                                                                                                  \n",
      " expanded_conv_1/expand (Conv2D  (None, 15, 20, 40)  320         ['expanded_conv/project/BatchNorm\n",
      " )                                                               [0][0]']                         \n",
      "                                                                                                  \n",
      " expanded_conv_1/expand/BatchNo  (None, 15, 20, 40)  160         ['expanded_conv_1/expand[0][0]'] \n",
      " rm (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " re_lu_42 (ReLU)                (None, 15, 20, 40)   0           ['expanded_conv_1/expand/BatchNor\n",
      "                                                                 m[0][0]']                        \n",
      "                                                                                                  \n",
      " expanded_conv_1/depthwise/pad   (None, 17, 21, 40)  0           ['re_lu_42[0][0]']               \n",
      " (ZeroPadding2D)                                                                                  \n",
      "                                                                                                  \n",
      " expanded_conv_1/depthwise (Dep  (None, 8, 10, 40)   360         ['expanded_conv_1/depthwise/pad[0\n",
      " thwiseConv2D)                                                   ][0]']                           \n",
      "                                                                                                  \n",
      " expanded_conv_1/depthwise/Batc  (None, 8, 10, 40)   160         ['expanded_conv_1/depthwise[0][0]\n",
      " hNorm (BatchNormalization)                                      ']                               \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " re_lu_43 (ReLU)                (None, 8, 10, 40)    0           ['expanded_conv_1/depthwise/Batch\n",
      "                                                                 Norm[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_1/project (Conv2  (None, 8, 10, 8)    320         ['re_lu_43[0][0]']               \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_1/project/BatchN  (None, 8, 10, 8)    32          ['expanded_conv_1/project[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " expanded_conv_2/expand (Conv2D  (None, 8, 10, 32)   256         ['expanded_conv_1/project/BatchNo\n",
      " )                                                               rm[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv_2/expand/BatchNo  (None, 8, 10, 32)   128         ['expanded_conv_2/expand[0][0]'] \n",
      " rm (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " re_lu_44 (ReLU)                (None, 8, 10, 32)    0           ['expanded_conv_2/expand/BatchNor\n",
      "                                                                 m[0][0]']                        \n",
      "                                                                                                  \n",
      " expanded_conv_2/depthwise (Dep  (None, 8, 10, 32)   288         ['re_lu_44[0][0]']               \n",
      " thwiseConv2D)                                                                                    \n",
      "                                                                                                  \n",
      " expanded_conv_2/depthwise/Batc  (None, 8, 10, 32)   128         ['expanded_conv_2/depthwise[0][0]\n",
      " hNorm (BatchNormalization)                                      ']                               \n",
      "                                                                                                  \n",
      " re_lu_45 (ReLU)                (None, 8, 10, 32)    0           ['expanded_conv_2/depthwise/Batch\n",
      "                                                                 Norm[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_2/project (Conv2  (None, 8, 10, 8)    256         ['re_lu_45[0][0]']               \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_2/project/BatchN  (None, 8, 10, 8)    32          ['expanded_conv_2/project[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " expanded_conv_2/Add (Add)      (None, 8, 10, 8)     0           ['expanded_conv_1/project/BatchNo\n",
      "                                                                 rm[0][0]',                       \n",
      "                                                                  'expanded_conv_2/project/BatchNo\n",
      "                                                                 rm[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv_3/expand (Conv2D  (None, 8, 10, 32)   256         ['expanded_conv_2/Add[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv_3/expand/BatchNo  (None, 8, 10, 32)   128         ['expanded_conv_3/expand[0][0]'] \n",
      " rm (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_30 (TFOpL  (None, 8, 10, 32)   0           ['expanded_conv_3/expand/BatchNor\n",
      " ambda)                                                          m[0][0]']                        \n",
      "                                                                                                  \n",
      " re_lu_46 (ReLU)                (None, 8, 10, 32)    0           ['tf.__operators__.add_30[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_30 (TFOpLambd  (None, 8, 10, 32)   0           ['re_lu_46[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " multiply_21 (Multiply)         (None, 8, 10, 32)    0           ['expanded_conv_3/expand/BatchNor\n",
      "                                                                 m[0][0]',                        \n",
      "                                                                  'tf.math.multiply_30[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_3/depthwise/pad   (None, 11, 13, 32)  0           ['multiply_21[0][0]']            \n",
      " (ZeroPadding2D)                                                                                  \n",
      "                                                                                                  \n",
      " expanded_conv_3/depthwise (Dep  (None, 4, 5, 32)    800         ['expanded_conv_3/depthwise/pad[0\n",
      " thwiseConv2D)                                                   ][0]']                           \n",
      "                                                                                                  \n",
      " expanded_conv_3/depthwise/Batc  (None, 4, 5, 32)    128         ['expanded_conv_3/depthwise[0][0]\n",
      " hNorm (BatchNormalization)                                      ']                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_31 (TFOpL  (None, 4, 5, 32)    0           ['expanded_conv_3/depthwise/Batch\n",
      " ambda)                                                          Norm[0][0]']                     \n",
      "                                                                                                  \n",
      " re_lu_47 (ReLU)                (None, 4, 5, 32)     0           ['tf.__operators__.add_31[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_31 (TFOpLambd  (None, 4, 5, 32)    0           ['re_lu_47[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " multiply_22 (Multiply)         (None, 4, 5, 32)     0           ['expanded_conv_3/depthwise/Batch\n",
      "                                                                 Norm[0][0]',                     \n",
      "                                                                  'tf.math.multiply_31[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_3/squeeze_excite  (None, 1, 1, 32)    0           ['multiply_22[0][0]']            \n",
      " /AvgPool (GlobalAveragePooling                                                                   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " expanded_conv_3/squeeze_excite  (None, 1, 1, 8)     264         ['expanded_conv_3/squeeze_excite/\n",
      " /Conv (Conv2D)                                                  AvgPool[0][0]']                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " expanded_conv_3/squeeze_excite  (None, 1, 1, 8)     0           ['expanded_conv_3/squeeze_excite/\n",
      " /Relu (ReLU)                                                    Conv[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_3/squeeze_excite  (None, 1, 1, 32)    288         ['expanded_conv_3/squeeze_excite/\n",
      " /Conv_1 (Conv2D)                                                Relu[0][0]']                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_32 (TFOpL  (None, 1, 1, 32)    0           ['expanded_conv_3/squeeze_excite/\n",
      " ambda)                                                          Conv_1[0][0]']                   \n",
      "                                                                                                  \n",
      " re_lu_48 (ReLU)                (None, 1, 1, 32)     0           ['tf.__operators__.add_32[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_32 (TFOpLambd  (None, 1, 1, 32)    0           ['re_lu_48[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_3/squeeze_excite  (None, 4, 5, 32)    0           ['multiply_22[0][0]',            \n",
      " /Mul (Multiply)                                                  'tf.math.multiply_32[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_3/project (Conv2  (None, 4, 5, 8)     256         ['expanded_conv_3/squeeze_excite/\n",
      " D)                                                              Mul[0][0]']                      \n",
      "                                                                                                  \n",
      " expanded_conv_3/project/BatchN  (None, 4, 5, 8)     32          ['expanded_conv_3/project[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " expanded_conv_4/expand (Conv2D  (None, 4, 5, 48)    384         ['expanded_conv_3/project/BatchNo\n",
      " )                                                               rm[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv_4/expand/BatchNo  (None, 4, 5, 48)    192         ['expanded_conv_4/expand[0][0]'] \n",
      " rm (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_33 (TFOpL  (None, 4, 5, 48)    0           ['expanded_conv_4/expand/BatchNor\n",
      " ambda)                                                          m[0][0]']                        \n",
      "                                                                                                  \n",
      " re_lu_49 (ReLU)                (None, 4, 5, 48)     0           ['tf.__operators__.add_33[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_33 (TFOpLambd  (None, 4, 5, 48)    0           ['re_lu_49[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " multiply_23 (Multiply)         (None, 4, 5, 48)     0           ['expanded_conv_4/expand/BatchNor\n",
      "                                                                 m[0][0]',                        \n",
      "                                                                  'tf.math.multiply_33[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_4/depthwise (Dep  (None, 4, 5, 48)    1200        ['multiply_23[0][0]']            \n",
      " thwiseConv2D)                                                                                    \n",
      "                                                                                                  \n",
      " expanded_conv_4/depthwise/Batc  (None, 4, 5, 48)    192         ['expanded_conv_4/depthwise[0][0]\n",
      " hNorm (BatchNormalization)                                      ']                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_34 (TFOpL  (None, 4, 5, 48)    0           ['expanded_conv_4/depthwise/Batch\n",
      " ambda)                                                          Norm[0][0]']                     \n",
      "                                                                                                  \n",
      " re_lu_50 (ReLU)                (None, 4, 5, 48)     0           ['tf.__operators__.add_34[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_34 (TFOpLambd  (None, 4, 5, 48)    0           ['re_lu_50[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " multiply_24 (Multiply)         (None, 4, 5, 48)     0           ['expanded_conv_4/depthwise/Batch\n",
      "                                                                 Norm[0][0]',                     \n",
      "                                                                  'tf.math.multiply_34[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_4/squeeze_excite  (None, 1, 1, 48)    0           ['multiply_24[0][0]']            \n",
      " /AvgPool (GlobalAveragePooling                                                                   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " expanded_conv_4/squeeze_excite  (None, 1, 1, 16)    784         ['expanded_conv_4/squeeze_excite/\n",
      " /Conv (Conv2D)                                                  AvgPool[0][0]']                  \n",
      "                                                                                                  \n",
      " expanded_conv_4/squeeze_excite  (None, 1, 1, 16)    0           ['expanded_conv_4/squeeze_excite/\n",
      " /Relu (ReLU)                                                    Conv[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_4/squeeze_excite  (None, 1, 1, 48)    816         ['expanded_conv_4/squeeze_excite/\n",
      " /Conv_1 (Conv2D)                                                Relu[0][0]']                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_35 (TFOpL  (None, 1, 1, 48)    0           ['expanded_conv_4/squeeze_excite/\n",
      " ambda)                                                          Conv_1[0][0]']                   \n",
      "                                                                                                  \n",
      " re_lu_51 (ReLU)                (None, 1, 1, 48)     0           ['tf.__operators__.add_35[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_35 (TFOpLambd  (None, 1, 1, 48)    0           ['re_lu_51[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_4/squeeze_excite  (None, 4, 5, 48)    0           ['multiply_24[0][0]',            \n",
      " /Mul (Multiply)                                                  'tf.math.multiply_35[0][0]']    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " expanded_conv_4/project (Conv2  (None, 4, 5, 8)     384         ['expanded_conv_4/squeeze_excite/\n",
      " D)                                                              Mul[0][0]']                      \n",
      "                                                                                                  \n",
      " expanded_conv_4/project/BatchN  (None, 4, 5, 8)     32          ['expanded_conv_4/project[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " expanded_conv_4/Add (Add)      (None, 4, 5, 8)      0           ['expanded_conv_3/project/BatchNo\n",
      "                                                                 rm[0][0]',                       \n",
      "                                                                  'expanded_conv_4/project/BatchNo\n",
      "                                                                 rm[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv_5/expand (Conv2D  (None, 4, 5, 48)    384         ['expanded_conv_4/Add[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv_5/expand/BatchNo  (None, 4, 5, 48)    192         ['expanded_conv_5/expand[0][0]'] \n",
      " rm (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_36 (TFOpL  (None, 4, 5, 48)    0           ['expanded_conv_5/expand/BatchNor\n",
      " ambda)                                                          m[0][0]']                        \n",
      "                                                                                                  \n",
      " re_lu_52 (ReLU)                (None, 4, 5, 48)     0           ['tf.__operators__.add_36[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_36 (TFOpLambd  (None, 4, 5, 48)    0           ['re_lu_52[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " multiply_25 (Multiply)         (None, 4, 5, 48)     0           ['expanded_conv_5/expand/BatchNor\n",
      "                                                                 m[0][0]',                        \n",
      "                                                                  'tf.math.multiply_36[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_5/depthwise (Dep  (None, 4, 5, 48)    1200        ['multiply_25[0][0]']            \n",
      " thwiseConv2D)                                                                                    \n",
      "                                                                                                  \n",
      " expanded_conv_5/depthwise/Batc  (None, 4, 5, 48)    192         ['expanded_conv_5/depthwise[0][0]\n",
      " hNorm (BatchNormalization)                                      ']                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_37 (TFOpL  (None, 4, 5, 48)    0           ['expanded_conv_5/depthwise/Batch\n",
      " ambda)                                                          Norm[0][0]']                     \n",
      "                                                                                                  \n",
      " re_lu_53 (ReLU)                (None, 4, 5, 48)     0           ['tf.__operators__.add_37[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_37 (TFOpLambd  (None, 4, 5, 48)    0           ['re_lu_53[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " multiply_26 (Multiply)         (None, 4, 5, 48)     0           ['expanded_conv_5/depthwise/Batch\n",
      "                                                                 Norm[0][0]',                     \n",
      "                                                                  'tf.math.multiply_37[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_5/squeeze_excite  (None, 1, 1, 48)    0           ['multiply_26[0][0]']            \n",
      " /AvgPool (GlobalAveragePooling                                                                   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " expanded_conv_5/squeeze_excite  (None, 1, 1, 16)    784         ['expanded_conv_5/squeeze_excite/\n",
      " /Conv (Conv2D)                                                  AvgPool[0][0]']                  \n",
      "                                                                                                  \n",
      " expanded_conv_5/squeeze_excite  (None, 1, 1, 16)    0           ['expanded_conv_5/squeeze_excite/\n",
      " /Relu (ReLU)                                                    Conv[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_5/squeeze_excite  (None, 1, 1, 48)    816         ['expanded_conv_5/squeeze_excite/\n",
      " /Conv_1 (Conv2D)                                                Relu[0][0]']                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_38 (TFOpL  (None, 1, 1, 48)    0           ['expanded_conv_5/squeeze_excite/\n",
      " ambda)                                                          Conv_1[0][0]']                   \n",
      "                                                                                                  \n",
      " re_lu_54 (ReLU)                (None, 1, 1, 48)     0           ['tf.__operators__.add_38[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_38 (TFOpLambd  (None, 1, 1, 48)    0           ['re_lu_54[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_5/squeeze_excite  (None, 4, 5, 48)    0           ['multiply_26[0][0]',            \n",
      " /Mul (Multiply)                                                  'tf.math.multiply_38[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_5/project (Conv2  (None, 4, 5, 8)     384         ['expanded_conv_5/squeeze_excite/\n",
      " D)                                                              Mul[0][0]']                      \n",
      "                                                                                                  \n",
      " expanded_conv_5/project/BatchN  (None, 4, 5, 8)     32          ['expanded_conv_5/project[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " expanded_conv_5/Add (Add)      (None, 4, 5, 8)      0           ['expanded_conv_4/Add[0][0]',    \n",
      "                                                                  'expanded_conv_5/project/BatchNo\n",
      "                                                                 rm[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv_6/expand (Conv2D  (None, 4, 5, 24)    192         ['expanded_conv_5/Add[0][0]']    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " )                                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv_6/expand/BatchNo  (None, 4, 5, 24)    96          ['expanded_conv_6/expand[0][0]'] \n",
      " rm (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_39 (TFOpL  (None, 4, 5, 24)    0           ['expanded_conv_6/expand/BatchNor\n",
      " ambda)                                                          m[0][0]']                        \n",
      "                                                                                                  \n",
      " re_lu_55 (ReLU)                (None, 4, 5, 24)     0           ['tf.__operators__.add_39[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_39 (TFOpLambd  (None, 4, 5, 24)    0           ['re_lu_55[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " multiply_27 (Multiply)         (None, 4, 5, 24)     0           ['expanded_conv_6/expand/BatchNor\n",
      "                                                                 m[0][0]',                        \n",
      "                                                                  'tf.math.multiply_39[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_6/depthwise (Dep  (None, 4, 5, 24)    600         ['multiply_27[0][0]']            \n",
      " thwiseConv2D)                                                                                    \n",
      "                                                                                                  \n",
      " expanded_conv_6/depthwise/Batc  (None, 4, 5, 24)    96          ['expanded_conv_6/depthwise[0][0]\n",
      " hNorm (BatchNormalization)                                      ']                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_40 (TFOpL  (None, 4, 5, 24)    0           ['expanded_conv_6/depthwise/Batch\n",
      " ambda)                                                          Norm[0][0]']                     \n",
      "                                                                                                  \n",
      " re_lu_56 (ReLU)                (None, 4, 5, 24)     0           ['tf.__operators__.add_40[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_40 (TFOpLambd  (None, 4, 5, 24)    0           ['re_lu_56[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " multiply_28 (Multiply)         (None, 4, 5, 24)     0           ['expanded_conv_6/depthwise/Batch\n",
      "                                                                 Norm[0][0]',                     \n",
      "                                                                  'tf.math.multiply_40[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_6/squeeze_excite  (None, 1, 1, 24)    0           ['multiply_28[0][0]']            \n",
      " /AvgPool (GlobalAveragePooling                                                                   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " expanded_conv_6/squeeze_excite  (None, 1, 1, 8)     200         ['expanded_conv_6/squeeze_excite/\n",
      " /Conv (Conv2D)                                                  AvgPool[0][0]']                  \n",
      "                                                                                                  \n",
      " expanded_conv_6/squeeze_excite  (None, 1, 1, 8)     0           ['expanded_conv_6/squeeze_excite/\n",
      " /Relu (ReLU)                                                    Conv[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_6/squeeze_excite  (None, 1, 1, 24)    216         ['expanded_conv_6/squeeze_excite/\n",
      " /Conv_1 (Conv2D)                                                Relu[0][0]']                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_41 (TFOpL  (None, 1, 1, 24)    0           ['expanded_conv_6/squeeze_excite/\n",
      " ambda)                                                          Conv_1[0][0]']                   \n",
      "                                                                                                  \n",
      " re_lu_57 (ReLU)                (None, 1, 1, 24)     0           ['tf.__operators__.add_41[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_41 (TFOpLambd  (None, 1, 1, 24)    0           ['re_lu_57[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_6/squeeze_excite  (None, 4, 5, 24)    0           ['multiply_28[0][0]',            \n",
      " /Mul (Multiply)                                                  'tf.math.multiply_41[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_6/project (Conv2  (None, 4, 5, 8)     192         ['expanded_conv_6/squeeze_excite/\n",
      " D)                                                              Mul[0][0]']                      \n",
      "                                                                                                  \n",
      " expanded_conv_6/project/BatchN  (None, 4, 5, 8)     32          ['expanded_conv_6/project[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " expanded_conv_6/Add (Add)      (None, 4, 5, 8)      0           ['expanded_conv_5/Add[0][0]',    \n",
      "                                                                  'expanded_conv_6/project/BatchNo\n",
      "                                                                 rm[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv_7/expand (Conv2D  (None, 4, 5, 24)    192         ['expanded_conv_6/Add[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv_7/expand/BatchNo  (None, 4, 5, 24)    96          ['expanded_conv_7/expand[0][0]'] \n",
      " rm (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_42 (TFOpL  (None, 4, 5, 24)    0           ['expanded_conv_7/expand/BatchNor\n",
      " ambda)                                                          m[0][0]']                        \n",
      "                                                                                                  \n",
      " re_lu_58 (ReLU)                (None, 4, 5, 24)     0           ['tf.__operators__.add_42[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_42 (TFOpLambd  (None, 4, 5, 24)    0           ['re_lu_58[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " multiply_29 (Multiply)         (None, 4, 5, 24)     0           ['expanded_conv_7/expand/BatchNor\n",
      "                                                                 m[0][0]',                        \n",
      "                                                                  'tf.math.multiply_42[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_7/depthwise (Dep  (None, 4, 5, 24)    600         ['multiply_29[0][0]']            \n",
      " thwiseConv2D)                                                                                    \n",
      "                                                                                                  \n",
      " expanded_conv_7/depthwise/Batc  (None, 4, 5, 24)    96          ['expanded_conv_7/depthwise[0][0]\n",
      " hNorm (BatchNormalization)                                      ']                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_43 (TFOpL  (None, 4, 5, 24)    0           ['expanded_conv_7/depthwise/Batch\n",
      " ambda)                                                          Norm[0][0]']                     \n",
      "                                                                                                  \n",
      " re_lu_59 (ReLU)                (None, 4, 5, 24)     0           ['tf.__operators__.add_43[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_43 (TFOpLambd  (None, 4, 5, 24)    0           ['re_lu_59[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " multiply_30 (Multiply)         (None, 4, 5, 24)     0           ['expanded_conv_7/depthwise/Batch\n",
      "                                                                 Norm[0][0]',                     \n",
      "                                                                  'tf.math.multiply_43[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_7/squeeze_excite  (None, 1, 1, 24)    0           ['multiply_30[0][0]']            \n",
      " /AvgPool (GlobalAveragePooling                                                                   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " expanded_conv_7/squeeze_excite  (None, 1, 1, 8)     200         ['expanded_conv_7/squeeze_excite/\n",
      " /Conv (Conv2D)                                                  AvgPool[0][0]']                  \n",
      "                                                                                                  \n",
      " expanded_conv_7/squeeze_excite  (None, 1, 1, 8)     0           ['expanded_conv_7/squeeze_excite/\n",
      " /Relu (ReLU)                                                    Conv[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_7/squeeze_excite  (None, 1, 1, 24)    216         ['expanded_conv_7/squeeze_excite/\n",
      " /Conv_1 (Conv2D)                                                Relu[0][0]']                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_44 (TFOpL  (None, 1, 1, 24)    0           ['expanded_conv_7/squeeze_excite/\n",
      " ambda)                                                          Conv_1[0][0]']                   \n",
      "                                                                                                  \n",
      " re_lu_60 (ReLU)                (None, 1, 1, 24)     0           ['tf.__operators__.add_44[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_44 (TFOpLambd  (None, 1, 1, 24)    0           ['re_lu_60[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_7/squeeze_excite  (None, 4, 5, 24)    0           ['multiply_30[0][0]',            \n",
      " /Mul (Multiply)                                                  'tf.math.multiply_44[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_7/project (Conv2  (None, 4, 5, 8)     192         ['expanded_conv_7/squeeze_excite/\n",
      " D)                                                              Mul[0][0]']                      \n",
      "                                                                                                  \n",
      " expanded_conv_7/project/BatchN  (None, 4, 5, 8)     32          ['expanded_conv_7/project[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " expanded_conv_7/Add (Add)      (None, 4, 5, 8)      0           ['expanded_conv_6/Add[0][0]',    \n",
      "                                                                  'expanded_conv_7/project/BatchNo\n",
      "                                                                 rm[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv_8/expand (Conv2D  (None, 4, 5, 48)    384         ['expanded_conv_7/Add[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv_8/expand/BatchNo  (None, 4, 5, 48)    192         ['expanded_conv_8/expand[0][0]'] \n",
      " rm (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_45 (TFOpL  (None, 4, 5, 48)    0           ['expanded_conv_8/expand/BatchNor\n",
      " ambda)                                                          m[0][0]']                        \n",
      "                                                                                                  \n",
      " re_lu_61 (ReLU)                (None, 4, 5, 48)     0           ['tf.__operators__.add_45[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_45 (TFOpLambd  (None, 4, 5, 48)    0           ['re_lu_61[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " multiply_31 (Multiply)         (None, 4, 5, 48)     0           ['expanded_conv_8/expand/BatchNor\n",
      "                                                                 m[0][0]',                        \n",
      "                                                                  'tf.math.multiply_45[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_8/depthwise/pad   (None, 7, 9, 48)    0           ['multiply_31[0][0]']            \n",
      " (ZeroPadding2D)                                                                                  \n",
      "                                                                                                  \n",
      " expanded_conv_8/depthwise (Dep  (None, 2, 3, 48)    1200        ['expanded_conv_8/depthwise/pad[0\n",
      " thwiseConv2D)                                                   ][0]']                           \n",
      "                                                                                                  \n",
      " expanded_conv_8/depthwise/Batc  (None, 2, 3, 48)    192         ['expanded_conv_8/depthwise[0][0]\n",
      " hNorm (BatchNormalization)                                      ']                               \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " tf.__operators__.add_46 (TFOpL  (None, 2, 3, 48)    0           ['expanded_conv_8/depthwise/Batch\n",
      " ambda)                                                          Norm[0][0]']                     \n",
      "                                                                                                  \n",
      " re_lu_62 (ReLU)                (None, 2, 3, 48)     0           ['tf.__operators__.add_46[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_46 (TFOpLambd  (None, 2, 3, 48)    0           ['re_lu_62[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " multiply_32 (Multiply)         (None, 2, 3, 48)     0           ['expanded_conv_8/depthwise/Batch\n",
      "                                                                 Norm[0][0]',                     \n",
      "                                                                  'tf.math.multiply_46[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_8/squeeze_excite  (None, 1, 1, 48)    0           ['multiply_32[0][0]']            \n",
      " /AvgPool (GlobalAveragePooling                                                                   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " expanded_conv_8/squeeze_excite  (None, 1, 1, 16)    784         ['expanded_conv_8/squeeze_excite/\n",
      " /Conv (Conv2D)                                                  AvgPool[0][0]']                  \n",
      "                                                                                                  \n",
      " expanded_conv_8/squeeze_excite  (None, 1, 1, 16)    0           ['expanded_conv_8/squeeze_excite/\n",
      " /Relu (ReLU)                                                    Conv[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_8/squeeze_excite  (None, 1, 1, 48)    816         ['expanded_conv_8/squeeze_excite/\n",
      " /Conv_1 (Conv2D)                                                Relu[0][0]']                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_47 (TFOpL  (None, 1, 1, 48)    0           ['expanded_conv_8/squeeze_excite/\n",
      " ambda)                                                          Conv_1[0][0]']                   \n",
      "                                                                                                  \n",
      " re_lu_63 (ReLU)                (None, 1, 1, 48)     0           ['tf.__operators__.add_47[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_47 (TFOpLambd  (None, 1, 1, 48)    0           ['re_lu_63[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_8/squeeze_excite  (None, 2, 3, 48)    0           ['multiply_32[0][0]',            \n",
      " /Mul (Multiply)                                                  'tf.math.multiply_47[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_8/project (Conv2  (None, 2, 3, 8)     384         ['expanded_conv_8/squeeze_excite/\n",
      " D)                                                              Mul[0][0]']                      \n",
      "                                                                                                  \n",
      " expanded_conv_8/project/BatchN  (None, 2, 3, 8)     32          ['expanded_conv_8/project[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " expanded_conv_9/expand (Conv2D  (None, 2, 3, 48)    384         ['expanded_conv_8/project/BatchNo\n",
      " )                                                               rm[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv_9/expand/BatchNo  (None, 2, 3, 48)    192         ['expanded_conv_9/expand[0][0]'] \n",
      " rm (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_48 (TFOpL  (None, 2, 3, 48)    0           ['expanded_conv_9/expand/BatchNor\n",
      " ambda)                                                          m[0][0]']                        \n",
      "                                                                                                  \n",
      " re_lu_64 (ReLU)                (None, 2, 3, 48)     0           ['tf.__operators__.add_48[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_48 (TFOpLambd  (None, 2, 3, 48)    0           ['re_lu_64[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " multiply_33 (Multiply)         (None, 2, 3, 48)     0           ['expanded_conv_9/expand/BatchNor\n",
      "                                                                 m[0][0]',                        \n",
      "                                                                  'tf.math.multiply_48[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_9/depthwise (Dep  (None, 2, 3, 48)    1200        ['multiply_33[0][0]']            \n",
      " thwiseConv2D)                                                                                    \n",
      "                                                                                                  \n",
      " expanded_conv_9/depthwise/Batc  (None, 2, 3, 48)    192         ['expanded_conv_9/depthwise[0][0]\n",
      " hNorm (BatchNormalization)                                      ']                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_49 (TFOpL  (None, 2, 3, 48)    0           ['expanded_conv_9/depthwise/Batch\n",
      " ambda)                                                          Norm[0][0]']                     \n",
      "                                                                                                  \n",
      " re_lu_65 (ReLU)                (None, 2, 3, 48)     0           ['tf.__operators__.add_49[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_49 (TFOpLambd  (None, 2, 3, 48)    0           ['re_lu_65[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " multiply_34 (Multiply)         (None, 2, 3, 48)     0           ['expanded_conv_9/depthwise/Batch\n",
      "                                                                 Norm[0][0]',                     \n",
      "                                                                  'tf.math.multiply_49[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_9/squeeze_excite  (None, 1, 1, 48)    0           ['multiply_34[0][0]']            \n",
      " /AvgPool (GlobalAveragePooling                                                                   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " expanded_conv_9/squeeze_excite  (None, 1, 1, 16)    784         ['expanded_conv_9/squeeze_excite/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " /Conv (Conv2D)                                                  AvgPool[0][0]']                  \n",
      "                                                                                                  \n",
      " expanded_conv_9/squeeze_excite  (None, 1, 1, 16)    0           ['expanded_conv_9/squeeze_excite/\n",
      " /Relu (ReLU)                                                    Conv[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_9/squeeze_excite  (None, 1, 1, 48)    816         ['expanded_conv_9/squeeze_excite/\n",
      " /Conv_1 (Conv2D)                                                Relu[0][0]']                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_50 (TFOpL  (None, 1, 1, 48)    0           ['expanded_conv_9/squeeze_excite/\n",
      " ambda)                                                          Conv_1[0][0]']                   \n",
      "                                                                                                  \n",
      " re_lu_66 (ReLU)                (None, 1, 1, 48)     0           ['tf.__operators__.add_50[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_50 (TFOpLambd  (None, 1, 1, 48)    0           ['re_lu_66[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_9/squeeze_excite  (None, 2, 3, 48)    0           ['multiply_34[0][0]',            \n",
      " /Mul (Multiply)                                                  'tf.math.multiply_50[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_9/project (Conv2  (None, 2, 3, 8)     384         ['expanded_conv_9/squeeze_excite/\n",
      " D)                                                              Mul[0][0]']                      \n",
      "                                                                                                  \n",
      " expanded_conv_9/project/BatchN  (None, 2, 3, 8)     32          ['expanded_conv_9/project[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " expanded_conv_9/Add (Add)      (None, 2, 3, 8)      0           ['expanded_conv_8/project/BatchNo\n",
      "                                                                 rm[0][0]',                       \n",
      "                                                                  'expanded_conv_9/project/BatchNo\n",
      "                                                                 rm[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv_10/expand (Conv2  (None, 2, 3, 48)    384         ['expanded_conv_9/Add[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_10/expand/BatchN  (None, 2, 3, 48)    192         ['expanded_conv_10/expand[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " tf.__operators__.add_51 (TFOpL  (None, 2, 3, 48)    0           ['expanded_conv_10/expand/BatchNo\n",
      " ambda)                                                          rm[0][0]']                       \n",
      "                                                                                                  \n",
      " re_lu_67 (ReLU)                (None, 2, 3, 48)     0           ['tf.__operators__.add_51[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_51 (TFOpLambd  (None, 2, 3, 48)    0           ['re_lu_67[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " multiply_35 (Multiply)         (None, 2, 3, 48)     0           ['expanded_conv_10/expand/BatchNo\n",
      "                                                                 rm[0][0]',                       \n",
      "                                                                  'tf.math.multiply_51[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_10/depthwise (De  (None, 2, 3, 48)    1200        ['multiply_35[0][0]']            \n",
      " pthwiseConv2D)                                                                                   \n",
      "                                                                                                  \n",
      " expanded_conv_10/depthwise/Bat  (None, 2, 3, 48)    192         ['expanded_conv_10/depthwise[0][0\n",
      " chNorm (BatchNormalization)                                     ]']                              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_52 (TFOpL  (None, 2, 3, 48)    0           ['expanded_conv_10/depthwise/Batc\n",
      " ambda)                                                          hNorm[0][0]']                    \n",
      "                                                                                                  \n",
      " re_lu_68 (ReLU)                (None, 2, 3, 48)     0           ['tf.__operators__.add_52[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_52 (TFOpLambd  (None, 2, 3, 48)    0           ['re_lu_68[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " multiply_36 (Multiply)         (None, 2, 3, 48)     0           ['expanded_conv_10/depthwise/Batc\n",
      "                                                                 hNorm[0][0]',                    \n",
      "                                                                  'tf.math.multiply_52[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_10/squeeze_excit  (None, 1, 1, 48)    0           ['multiply_36[0][0]']            \n",
      " e/AvgPool (GlobalAveragePoolin                                                                   \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " expanded_conv_10/squeeze_excit  (None, 1, 1, 16)    784         ['expanded_conv_10/squeeze_excite\n",
      " e/Conv (Conv2D)                                                 /AvgPool[0][0]']                 \n",
      "                                                                                                  \n",
      " expanded_conv_10/squeeze_excit  (None, 1, 1, 16)    0           ['expanded_conv_10/squeeze_excite\n",
      " e/Relu (ReLU)                                                   /Conv[0][0]']                    \n",
      "                                                                                                  \n",
      " expanded_conv_10/squeeze_excit  (None, 1, 1, 48)    816         ['expanded_conv_10/squeeze_excite\n",
      " e/Conv_1 (Conv2D)                                               /Relu[0][0]']                    \n",
      "                                                                                                  \n",
      " tf.__operators__.add_53 (TFOpL  (None, 1, 1, 48)    0           ['expanded_conv_10/squeeze_excite\n",
      " ambda)                                                          /Conv_1[0][0]']                  \n",
      "                                                                                                  \n",
      " re_lu_69 (ReLU)                (None, 1, 1, 48)     0           ['tf.__operators__.add_53[0][0]']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " tf.math.multiply_53 (TFOpLambd  (None, 1, 1, 48)    0           ['re_lu_69[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_10/squeeze_excit  (None, 2, 3, 48)    0           ['multiply_36[0][0]',            \n",
      " e/Mul (Multiply)                                                 'tf.math.multiply_53[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_10/project (Conv  (None, 2, 3, 8)     384         ['expanded_conv_10/squeeze_excite\n",
      " 2D)                                                             /Mul[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_10/project/Batch  (None, 2, 3, 8)     32          ['expanded_conv_10/project[0][0]'\n",
      " Norm (BatchNormalization)                                       ]                                \n",
      "                                                                                                  \n",
      " expanded_conv_10/Add (Add)     (None, 2, 3, 8)      0           ['expanded_conv_9/Add[0][0]',    \n",
      "                                                                  'expanded_conv_10/project/BatchN\n",
      "                                                                 orm[0][0]']                      \n",
      "                                                                                                  \n",
      " Conv_1 (Conv2D)                (None, 2, 3, 48)     384         ['expanded_conv_10/Add[0][0]']   \n",
      "                                                                                                  \n",
      " Conv_1/BatchNorm (BatchNormali  (None, 2, 3, 48)    192         ['Conv_1[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_54 (TFOpL  (None, 2, 3, 48)    0           ['Conv_1/BatchNorm[0][0]']       \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " re_lu_70 (ReLU)                (None, 2, 3, 48)     0           ['tf.__operators__.add_54[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_54 (TFOpLambd  (None, 2, 3, 48)    0           ['re_lu_70[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " multiply_37 (Multiply)         (None, 2, 3, 48)     0           ['Conv_1/BatchNorm[0][0]',       \n",
      "                                                                  'tf.math.multiply_54[0][0]']    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 29,480\n",
      "Trainable params: 27,576\n",
      "Non-trainable params: 1,904\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "24823cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(base_model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "03df6ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_20 (InputLayer)       [(None, 60, 80, 3)]       0         \n",
      "                                                                 \n",
      " rescaling_8 (Rescaling)     (None, 60, 80, 3)         0         \n",
      "                                                                 \n",
      " Conv (Conv2D)               (None, 30, 40, 16)        432       \n",
      "                                                                 \n",
      " Conv/BatchNorm (BatchNormal  (None, 30, 40, 16)       64        \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " re_lu_177 (ReLU)            (None, 30, 40, 16)        0         \n",
      "                                                                 \n",
      " expanded_conv/depthwise/pad  (None, 31, 41, 16)       0         \n",
      "  (ZeroPadding2D)                                                \n",
      "                                                                 \n",
      " expanded_conv/depthwise (De  (None, 15, 20, 16)       144       \n",
      " pthwiseConv2D)                                                  \n",
      "                                                                 \n",
      " expanded_conv/depthwise/Bat  (None, 15, 20, 16)       64        \n",
      " chNorm (BatchNormalization)                                     \n",
      "                                                                 \n",
      " re_lu_178 (ReLU)            (None, 15, 20, 16)        0         \n",
      "                                                                 \n",
      " expanded_conv/project (Conv  (None, 15, 20, 8)        128       \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " expanded_conv/project/Batch  (None, 15, 20, 8)        32        \n",
      " Norm (BatchNormalization)                                       \n",
      "                                                                 \n",
      " expanded_conv_1/expand (Con  (None, 15, 20, 40)       320       \n",
      " v2D)                                                            \n",
      "                                                                 \n",
      " expanded_conv_1/expand/Batc  (None, 15, 20, 40)       160       \n",
      " hNorm (BatchNormalization)                                      \n",
      "                                                                 \n",
      " re_lu_179 (ReLU)            (None, 15, 20, 40)        0         \n",
      "                                                                 \n",
      " expanded_conv_1/depthwise/p  (None, 17, 21, 40)       0         \n",
      " ad (ZeroPadding2D)                                              \n",
      "                                                                 \n",
      " expanded_conv_1/depthwise (  (None, 8, 10, 40)        360       \n",
      " DepthwiseConv2D)                                                \n",
      "                                                                 \n",
      " expanded_conv_1/depthwise/B  (None, 8, 10, 40)        160       \n",
      " atchNorm (BatchNormalizatio                                     \n",
      " n)                                                              \n",
      "                                                                 \n",
      " re_lu_180 (ReLU)            (None, 8, 10, 40)         0         \n",
      "                                                                 \n",
      " expanded_conv_1/project (Co  (None, 8, 10, 8)         320       \n",
      " nv2D)                                                           \n",
      "                                                                 \n",
      " expanded_conv_1/project/Bat  (None, 8, 10, 8)         32        \n",
      " chNorm (BatchNormalization)                                     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,216\n",
      "Trainable params: 1,960\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3bd8e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3249d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a8e630e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "27\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    for i in range(26, 102):\n",
    "        try:\n",
    "            layers_to_extract = base_model.layers[1:i]\n",
    "            inputs = tf.keras.Input(shape=MODEL_IMAGE_SHAPE )\n",
    "            x = inputs\n",
    "            for layer in layers_to_extract:\n",
    "                x = layer(x)\n",
    "            new_base_model = tf.keras.Model(inputs, x)\n",
    "            print(i)\n",
    "        except:\n",
    "            pass\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "910d2aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 60, 80, 3])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21776ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2814abbc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"expanded_conv_2/Add\" (type Add).\n\nA merge layer should be called on a list of inputs. Received: inputs=Tensor(\"Placeholder:0\", shape=(None, 8, 10, 8), dtype=float32) (not a list of tensors)\n\nCall arguments received by layer \"expanded_conv_2/Add\" (type Add):\n   inputs=tf.Tensor(shape=(None, 8, 10, 8), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [61]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m x \u001b[38;5;241m=\u001b[39m inputs\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m layers_to_extract:\n\u001b[0;32m----> 5\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m new_base_model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mModel(inputs, x)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(new_base_model\u001b[38;5;241m.\u001b[39msummary())\n",
      "File \u001b[0;32m~/anaconda3/envs/ai-env/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/ai-env/lib/python3.9/site-packages/keras/layers/merging/base_merge.py:123\u001b[0m, in \u001b[0;36m_Merge.call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs):\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m--> 123\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA merge layer should be called on a list of inputs. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    125\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: inputs=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minputs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (not a list of tensors)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    126\u001b[0m         )\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reshape_required:\n\u001b[1;32m    128\u001b[0m         reshaped_inputs \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"expanded_conv_2/Add\" (type Add).\n\nA merge layer should be called on a list of inputs. Received: inputs=Tensor(\"Placeholder:0\", shape=(None, 8, 10, 8), dtype=float32) (not a list of tensors)\n\nCall arguments received by layer \"expanded_conv_2/Add\" (type Add):\n   inputs=tf.Tensor(shape=(None, 8, 10, 8), dtype=float32)"
     ]
    }
   ],
   "source": [
    "layers_to_extract = base_model.layers[1:29]\n",
    "inputs = tf.keras.Input(shape=MODEL_IMAGE_SHAPE )\n",
    "x = inputs\n",
    "for layer in layers_to_extract:\n",
    "    x = layer(x)\n",
    "new_base_model = tf.keras.Model(inputs, x)\n",
    "\n",
    "print(new_base_model.summary())\n",
    "\n",
    "model = keras.Sequential([\n",
    "    new_base_model,\n",
    "    layers.DepthwiseConv2D(5,strides=(5,5),padding ='valid', use_bias = True),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(6),\n",
    "    \n",
    "#     layers.DepthwiseConv2D((3, 4),strides=(3,4),padding ='valid', use_bias = True),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.ReLU(6),\n",
    "    \n",
    "    #layers.GlobalAveragePooling2D(),\n",
    "    layers.Flatten(),\n",
    "#     layers.Dense(16, activation='relu'),\n",
    "#     layers.BatchNormalization(),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "37c3e91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 8, 10, 8)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0846f14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92f485e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d75005c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f34d928",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-30 10:29:52.636061: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-06-30 10:29:52.636139: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (glarus-pc): /proc/driver/nvidia/version does not exist\n",
      "2023-06-30 10:29:52.661475: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling (Rescaling)       (None, 60, 80, 3)         0         \n",
      "                                                                 \n",
      " depthwise_conv2d (Depthwise  (None, 29, 39, 3)        30        \n",
      " Conv2D)                                                         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 29, 39, 3)        12        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 14, 19, 8)         224       \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 14, 19, 8)         0         \n",
      "                                                                 \n",
      " depthwise_conv2d_1 (Depthwi  (None, 6, 9, 8)          80        \n",
      " seConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 6, 9, 8)          32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 6, 9, 8)           0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 2, 4, 16)          1168      \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 2, 4, 16)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,933\n",
      "Trainable params: 1,911\n",
      "Non-trainable params: 22\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=MODEL_IMAGE_SHAPE),\n",
    "    tf.keras.layers.Rescaling(1./255), \n",
    "    \n",
    "    layers.DepthwiseConv2D(3,strides=(2,2),padding ='valid', use_bias = True),\n",
    "    layers.BatchNormalization(),\n",
    "#     layers.ReLU(6),\n",
    "    \n",
    "    layers.Conv2D(8, 3,strides=(2, 2),padding ='valid', use_bias = True),\n",
    "#     layers.BatchNormalization(),\n",
    "    layers.ReLU(6),\n",
    "    \n",
    "    layers.DepthwiseConv2D(3,strides=(2,2),padding ='valid', use_bias = True),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(6),\n",
    "    \n",
    "    layers.Conv2D(16, 3,strides=(2,2),padding ='valid', use_bias = True),\n",
    "#     layers.BatchNormalization(),\n",
    "    layers.ReLU(6),\n",
    "    \n",
    "#     layers.DepthwiseConv2D(3,strides=(2,2),padding ='valid', use_bias = True),\n",
    "# #     layers.BatchNormalization(),\n",
    "#     layers.ReLU(6),    \n",
    "\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.ReLU(6),\n",
    "\n",
    "    \n",
    "#     layers.DepthwiseConv2D(3,strides=(2,2),padding ='valid', use_bias = True),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.ReLU(6),\n",
    "    \n",
    "#     layers.DepthwiseConv2D(3,strides=(3,3),padding ='valid', use_bias = True),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.ReLU(6),\n",
    "    \n",
    "    #layers.GlobalAveragePooling2D(),\n",
    "    layers.Flatten(),\n",
    "#     layers.Dense(16, activation='relu'),\n",
    "#     layers.BatchNormalization(),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9759fec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8a05f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6e8f88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1818ce84",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b2b8c60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "198/199 [============================>.] - ETA: 0s - loss: 1.2803 - sparse_categorical_accuracy: 0.3786\n",
      "Epoch 1: val_sparse_categorical_accuracy improved from -inf to 0.33333, saving model to image_classification_checkpoint.h5\n",
      "199/199 [==============================] - 11s 31ms/step - loss: 1.2799 - sparse_categorical_accuracy: 0.3785 - val_loss: 1.0988 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 2/10\n",
      "198/199 [============================>.] - ETA: 0s - loss: 1.1693 - sparse_categorical_accuracy: 0.4439\n",
      "Epoch 2: val_sparse_categorical_accuracy did not improve from 0.33333\n",
      "199/199 [==============================] - 6s 28ms/step - loss: 1.1696 - sparse_categorical_accuracy: 0.4438 - val_loss: 1.0996 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 3/10\n",
      "198/199 [============================>.] - ETA: 0s - loss: 0.9612 - sparse_categorical_accuracy: 0.5751\n",
      "Epoch 3: val_sparse_categorical_accuracy did not improve from 0.33333\n",
      "199/199 [==============================] - 6s 29ms/step - loss: 0.9587 - sparse_categorical_accuracy: 0.5763 - val_loss: 1.1063 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 4/10\n",
      "198/199 [============================>.] - ETA: 0s - loss: 0.7849 - sparse_categorical_accuracy: 0.6674\n",
      "Epoch 4: val_sparse_categorical_accuracy did not improve from 0.33333\n",
      "199/199 [==============================] - 6s 28ms/step - loss: 0.7842 - sparse_categorical_accuracy: 0.6675 - val_loss: 1.1147 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 5/10\n",
      "198/199 [============================>.] - ETA: 0s - loss: 0.7033 - sparse_categorical_accuracy: 0.7102\n",
      "Epoch 5: val_sparse_categorical_accuracy did not improve from 0.33333\n",
      "199/199 [==============================] - 6s 28ms/step - loss: 0.7035 - sparse_categorical_accuracy: 0.7098 - val_loss: 1.1284 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 6/10\n",
      "198/199 [============================>.] - ETA: 0s - loss: 0.6465 - sparse_categorical_accuracy: 0.7334\n",
      "Epoch 6: val_sparse_categorical_accuracy did not improve from 0.33333\n",
      "199/199 [==============================] - 6s 28ms/step - loss: 0.6464 - sparse_categorical_accuracy: 0.7325 - val_loss: 1.1290 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 7/10\n",
      "198/199 [============================>.] - ETA: 0s - loss: 0.5812 - sparse_categorical_accuracy: 0.7698\n",
      "Epoch 7: val_sparse_categorical_accuracy did not improve from 0.33333\n",
      "199/199 [==============================] - 6s 29ms/step - loss: 0.5811 - sparse_categorical_accuracy: 0.7697 - val_loss: 1.1397 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 8/10\n",
      "198/199 [============================>.] - ETA: 0s - loss: 0.5655 - sparse_categorical_accuracy: 0.7705\n",
      "Epoch 8: val_sparse_categorical_accuracy did not improve from 0.33333\n",
      "199/199 [==============================] - 6s 28ms/step - loss: 0.5656 - sparse_categorical_accuracy: 0.7697 - val_loss: 1.1495 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 9/10\n",
      "198/199 [============================>.] - ETA: 0s - loss: 0.5071 - sparse_categorical_accuracy: 0.8015\n",
      "Epoch 9: val_sparse_categorical_accuracy did not improve from 0.33333\n",
      "199/199 [==============================] - 6s 28ms/step - loss: 0.5105 - sparse_categorical_accuracy: 0.8009 - val_loss: 1.1597 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 10/10\n",
      "198/199 [============================>.] - ETA: 0s - loss: 0.4905 - sparse_categorical_accuracy: 0.8215\n",
      "Epoch 10: val_sparse_categorical_accuracy did not improve from 0.33333\n",
      "199/199 [==============================] - 6s 28ms/step - loss: 0.4902 - sparse_categorical_accuracy: 0.8211 - val_loss: 1.1531 - val_sparse_categorical_accuracy: 0.3333\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"image_classification_checkpoint.h5\",\n",
    "                             monitor='val_sparse_categorical_accuracy',\n",
    "                             mode='max',\n",
    "                             save_best_only=True,verbose=1)\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_accuracy',\n",
    "                          min_delta=0,\n",
    "                          patience=5,\n",
    "                          verbose=1,\n",
    "                          restore_best_weights=True)\n",
    "\n",
    "# callbacks=[checkpoint,earlystop]\n",
    "callbacks=[checkpoint]\n",
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "                   optimizer=Adam(learning_rate=0.001),\n",
    "                   metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "epochs=10\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "history = model.fit(     train_generator,\n",
    "                        #  steps_per_epoch=num_train_samples//batch_size,\n",
    "                         epochs=epochs,\n",
    "                        #validation_split=0.15,\n",
    "                        callbacks=callbacks,\n",
    "                         validation_data=val_generator,\n",
    "                        #  validation_steps=num_val_samples//batch_size\n",
    "                        class_weight=class_weights,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6f5f06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea243a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load the .h5 model\n",
    "model = load_model('image_classification_checkpoint.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3c75f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b436ee4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================== epoch 0 =======================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [52]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m===================== epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m =======================\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m inputs, targets \u001b[38;5;129;01min\u001b[39;00m train_generator:\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;66;03m#noisy_inputs = apply_gaussian_noise(inputs)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m         model\u001b[38;5;241m.\u001b[39mtrain_on_batch(inputs, targets)\n",
      "File \u001b[0;32m~/anaconda3/envs/ai-env/lib/python3.9/site-packages/keras/preprocessing/image.py:156\u001b[0m, in \u001b[0;36mIterator.__next__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ai-env/lib/python3.9/site-packages/keras/preprocessing/image.py:168\u001b[0m, in \u001b[0;36mIterator.next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    165\u001b[0m     index_array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_generator)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# The transformation of images is not under thread lock\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m# so it can be done in parallel\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_batches_of_transformed_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_array\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ai-env/lib/python3.9/site-packages/keras/preprocessing/image.py:384\u001b[0m, in \u001b[0;36mBatchFromFilesMixin._get_batches_of_transformed_samples\u001b[0;34m(self, index_array)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_data_generator:\n\u001b[1;32m    383\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_data_generator\u001b[38;5;241m.\u001b[39mget_random_transform(x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m--> 384\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_data_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_data_generator\u001b[38;5;241m.\u001b[39mstandardize(x)\n\u001b[1;32m    386\u001b[0m batch_x[i] \u001b[38;5;241m=\u001b[39m x\n",
      "File \u001b[0;32m~/anaconda3/envs/ai-env/lib/python3.9/site-packages/keras/preprocessing/image.py:2011\u001b[0m, in \u001b[0;36mImageDataGenerator.apply_transform\u001b[0;34m(self, x, transform_parameters)\u001b[0m\n\u001b[1;32m   2008\u001b[0m img_col_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcol_axis \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2009\u001b[0m img_channel_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchannel_axis \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 2011\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mapply_affine_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2012\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2013\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_parameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtheta\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2014\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_parameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2015\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_parameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2016\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_parameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2017\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_parameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_parameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2019\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrow_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_row_axis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2020\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcol_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_col_axis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2021\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchannel_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_channel_axis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2022\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfill_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2024\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolation_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2025\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2027\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transform_parameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchannel_shift_intensity\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2028\u001b[0m     x \u001b[38;5;241m=\u001b[39m apply_channel_shift(\n\u001b[1;32m   2029\u001b[0m         x,\n\u001b[1;32m   2030\u001b[0m         transform_parameters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchannel_shift_intensity\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   2031\u001b[0m         img_channel_axis,\n\u001b[1;32m   2032\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/ai-env/lib/python3.9/site-packages/keras/preprocessing/image.py:2609\u001b[0m, in \u001b[0;36mapply_affine_transform\u001b[0;34m(x, theta, tx, ty, shear, zx, zy, row_axis, col_axis, channel_axis, fill_mode, cval, order)\u001b[0m\n\u001b[1;32m   2606\u001b[0m final_affine_matrix \u001b[38;5;241m=\u001b[39m transform_matrix[:\u001b[38;5;241m2\u001b[39m, :\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m   2607\u001b[0m final_offset \u001b[38;5;241m=\u001b[39m transform_matrix[:\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m-> 2609\u001b[0m channel_images \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   2610\u001b[0m     ndimage\u001b[38;5;241m.\u001b[39minterpolation\u001b[38;5;241m.\u001b[39maffine_transform(\n\u001b[1;32m   2611\u001b[0m         x_channel,\n\u001b[1;32m   2612\u001b[0m         final_affine_matrix,\n\u001b[1;32m   2613\u001b[0m         final_offset,\n\u001b[1;32m   2614\u001b[0m         order\u001b[38;5;241m=\u001b[39morder,\n\u001b[1;32m   2615\u001b[0m         mode\u001b[38;5;241m=\u001b[39mfill_mode,\n\u001b[1;32m   2616\u001b[0m         cval\u001b[38;5;241m=\u001b[39mcval,\n\u001b[1;32m   2617\u001b[0m     )\n\u001b[1;32m   2618\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x_channel \u001b[38;5;129;01min\u001b[39;00m x\n\u001b[1;32m   2619\u001b[0m ]\n\u001b[1;32m   2620\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack(channel_images, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   2621\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrollaxis(x, \u001b[38;5;241m0\u001b[39m, channel_axis \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ai-env/lib/python3.9/site-packages/keras/preprocessing/image.py:2610\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2606\u001b[0m final_affine_matrix \u001b[38;5;241m=\u001b[39m transform_matrix[:\u001b[38;5;241m2\u001b[39m, :\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m   2607\u001b[0m final_offset \u001b[38;5;241m=\u001b[39m transform_matrix[:\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m   2609\u001b[0m channel_images \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m-> 2610\u001b[0m     \u001b[43mndimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maffine_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_channel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfinal_affine_matrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfinal_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2614\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2615\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2616\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2617\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2618\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x_channel \u001b[38;5;129;01min\u001b[39;00m x\n\u001b[1;32m   2619\u001b[0m ]\n\u001b[1;32m   2620\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack(channel_images, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   2621\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrollaxis(x, \u001b[38;5;241m0\u001b[39m, channel_axis \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ai-env/lib/python3.9/site-packages/scipy/ndimage/_interpolation.py:614\u001b[0m, in \u001b[0;36maffine_transform\u001b[0;34m(input, matrix, offset, output_shape, output, order, mode, cval, prefilter)\u001b[0m\n\u001b[1;32m    611\u001b[0m     _nd_image\u001b[38;5;241m.\u001b[39mzoom_shift(filtered, matrix, offset\u001b[38;5;241m/\u001b[39mmatrix, output, order,\n\u001b[1;32m    612\u001b[0m                          mode, cval, npad, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 614\u001b[0m     \u001b[43m_nd_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgeometric_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnpad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m                                  \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Function to apply Gaussian noise to each image in the batch\n",
    "def apply_gaussian_noise(image_batch):\n",
    "    noisy_batch = np.empty_like(image_batch)\n",
    "    for i, image in enumerate(image_batch):\n",
    "        noisy_batch[i] = random_noise(image, mode='gaussian', var=0.01)\n",
    "    return noisy_batch\n",
    "\n",
    "epochs = 100\n",
    "# Use the generator for training your model\n",
    "for epoch in range(epochs):\n",
    "    print(f\"===================== epoch {epoch} =======================\")\n",
    "    for inputs, targets in train_generator:\n",
    "        #noisy_inputs = apply_gaussian_noise(inputs)\n",
    "        model.train_on_batch(inputs, targets)\n",
    "#     for inputs, targets in val_generator:\n",
    "#             #\n",
    "#             result = model.evalute(inputs)   \n",
    "#             print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fd289ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/10]\n",
      "       Train Loss: 0.1655, Train Acc 0.8881999850273132\n",
      "[2/10]\n",
      "       Train Loss: 0.1151, Train Acc 0.892300009727478\n",
      "[3/10]\n",
      "       Train Loss: 0.1439, Train Acc 0.8851000070571899\n",
      "[4/10]\n",
      "       Train Loss: 0.2014, Train Acc 0.8705999851226807\n",
      "[5/10]\n",
      "       Train Loss: 0.1295, Train Acc 0.8791999816894531\n",
      "[6/10]\n",
      "       Train Loss: 0.1439, Train Acc 0.892799973487854\n",
      "[7/10]\n",
      "       Train Loss: 0.1151, Train Acc 0.890999972820282\n",
      "[8/10]\n",
      "       Train Loss: 0.1007, Train Acc 0.8863999843597412\n",
      "[9/10]\n",
      "       Train Loss: 0.1439, Train Acc 0.8877999782562256\n",
      "[10/10]\n",
      "       Train Loss: 0.1151, Train Acc 0.890999972820282\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "steps_per_epoch = len(train_generator)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "# Custom training loop\n",
    "for epoch in range(epochs):\n",
    "    print(f\"[{epoch + 1}/{epochs}]\")\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = tf.keras.metrics.SparseCategoricalAccuracy() \n",
    "    epoch_loss = 0\n",
    "    for step in range(steps_per_epoch):\n",
    "        inputs, targets = train_generator.next()\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Perform data augmentation\n",
    "            #noisy_inputs = ...  # Apply noise or other augmentations to inputs\n",
    "\n",
    "            # Forward pass\n",
    "            predictions = model(inputs)\n",
    "            loss_value = loss_fn(targets, predictions)\n",
    "            \n",
    "\n",
    "        # Compute gradients\n",
    "        gradients = tape.gradient(loss_value, model.trainable_weights)\n",
    "\n",
    "        # Update model weights\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "        \n",
    "        \n",
    "        epoch_loss += np.round(loss_value.numpy())\n",
    "        epoch_accuracy.update_state(targets, predictions)\n",
    "        \n",
    "    # Calculate training accuracy for the epoch\n",
    "    train_accuracy = epoch_accuracy.result()    \n",
    "    # Display training progress\n",
    "    print(f\"       Train Loss: {np.round(epoch_loss/steps_per_epoch, 4)}, Train Acc {np.round(train_accuracy.numpy(), 4)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6bae1672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139/139 [==============================] - 8s 56ms/step - loss: 0.2817 - sparse_categorical_accuracy: 0.8955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.28173503279685974, 0.8954750895500183]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a21262b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/300]\n",
      "          Train Loss 1.0, Train Acc 0.361\n",
      "          Val Loss 1.1683, Val Acc 0.3012\n",
      "\n",
      "[2/300]\n",
      "          Train Loss 1.0, Train Acc 0.3742\n",
      "          Val Loss 1.2115, Val Acc 0.265\n",
      "\n",
      "[3/300]\n",
      "          Train Loss 1.0, Train Acc 0.4398\n",
      "          Val Loss 1.3962, Val Acc 0.3534\n",
      "\n",
      "[4/300]\n",
      "          Train Loss 1.0, Train Acc 0.5529\n",
      "          Val Loss 1.2214, Val Acc 0.4698\n",
      "\n",
      "[5/300]\n",
      "          Train Loss 0.9784, Train Acc 0.6538\n",
      "          Val Loss 1.3946, Val Acc 0.4819\n",
      "\n",
      "[6/300]\n",
      "          Train Loss 0.9424, Train Acc 0.7\n",
      "          Val Loss 1.3819, Val Acc 0.4658\n",
      "\n",
      "[7/300]\n",
      "          Train Loss 0.8848, Train Acc 0.704\n",
      "          Val Loss 1.2276, Val Acc 0.518\n",
      "\n",
      "[8/300]\n",
      "          Train Loss 0.8489, Train Acc 0.7162\n",
      "          Val Loss 1.0449, Val Acc 0.51\n",
      "\n",
      "[9/300]\n",
      "          Train Loss 0.7985, Train Acc 0.723\n",
      "          Val Loss 1.3708, Val Acc 0.3815\n",
      "\n",
      "[10/300]\n",
      "          Train Loss 0.7985, Train Acc 0.7434\n",
      "          Val Loss 0.9979, Val Acc 0.5742\n",
      "\n",
      "[11/300]\n",
      "          Train Loss 0.7553, Train Acc 0.7647\n",
      "          Val Loss 1.1488, Val Acc 0.5301\n",
      "\n",
      "[12/300]\n",
      "          Train Loss 0.669, Train Acc 0.7628\n",
      "          Val Loss 1.1941, Val Acc 0.506\n",
      "\n",
      "[13/300]\n",
      "          Train Loss 0.633, Train Acc 0.7651\n",
      "          Val Loss 1.078, Val Acc 0.5783\n",
      "\n",
      "[14/300]\n",
      "          Train Loss 0.5683, Train Acc 0.7687\n",
      "          Val Loss 0.964, Val Acc 0.5742\n",
      "\n",
      "[15/300]\n",
      "          Train Loss 0.4748, Train Acc 0.7859\n",
      "          Val Loss 0.9202, Val Acc 0.5863\n",
      "\n",
      "[16/300]\n",
      "          Train Loss 0.6043, Train Acc 0.7918\n",
      "          Val Loss 0.8552, Val Acc 0.6144\n",
      "\n",
      "[17/300]\n",
      "          Train Loss 0.5323, Train Acc 0.7927\n",
      "          Val Loss 1.0561, Val Acc 0.5622\n",
      "\n",
      "[18/300]\n",
      "          Train Loss 0.5323, Train Acc 0.7981\n",
      "          Val Loss 1.0542, Val Acc 0.5542\n",
      "\n",
      "[19/300]\n",
      "          Train Loss 0.446, Train Acc 0.8162\n",
      "          Val Loss 1.3414, Val Acc 0.5301\n",
      "\n",
      "[20/300]\n",
      "          Train Loss 0.4748, Train Acc 0.8072\n",
      "          Val Loss 1.0898, Val Acc 0.5582\n",
      "\n",
      "[21/300]\n",
      "          Train Loss 0.482, Train Acc 0.799\n",
      "          Val Loss 0.8378, Val Acc 0.6064\n",
      "\n",
      "[22/300]\n",
      "          Train Loss 0.41, Train Acc 0.8104\n",
      "          Val Loss 1.1261, Val Acc 0.5742\n",
      "\n",
      "[23/300]\n",
      "          Train Loss 0.3093, Train Acc 0.8307\n",
      "          Val Loss 1.0229, Val Acc 0.6024\n",
      "\n",
      "[24/300]\n",
      "          Train Loss 0.4028, Train Acc 0.8144\n",
      "          Val Loss 1.0632, Val Acc 0.5903\n",
      "\n",
      "[25/300]\n",
      "          Train Loss 0.3309, Train Acc 0.8203\n",
      "          Val Loss 0.8133, Val Acc 0.6907\n",
      "\n",
      "[26/300]\n",
      "          Train Loss 0.5251, Train Acc 0.8013\n",
      "          Val Loss 0.9964, Val Acc 0.5983\n",
      "\n",
      "[27/300]\n",
      "          Train Loss 0.3597, Train Acc 0.8325\n",
      "          Val Loss 0.9159, Val Acc 0.6064\n",
      "\n",
      "[28/300]\n",
      "          Train Loss 0.3884, Train Acc 0.828\n",
      "          Val Loss 1.122, Val Acc 0.5662\n",
      "\n",
      "[29/300]\n",
      "          Train Loss 0.3956, Train Acc 0.8276\n",
      "          Val Loss 1.1546, Val Acc 0.5502\n",
      "\n",
      "[30/300]\n",
      "          Train Loss 0.3165, Train Acc 0.8307\n",
      "          Val Loss 0.923, Val Acc 0.6385\n",
      "\n",
      "[31/300]\n",
      "          Train Loss 0.2661, Train Acc 0.8366\n",
      "          Val Loss 0.872, Val Acc 0.6305\n",
      "\n",
      "[32/300]\n",
      "          Train Loss 0.3381, Train Acc 0.8348\n",
      "          Val Loss 0.9893, Val Acc 0.6064\n",
      "\n",
      "[33/300]\n",
      "          Train Loss 0.2877, Train Acc 0.8461\n",
      "          Val Loss 0.9009, Val Acc 0.6224\n",
      "\n",
      "[34/300]\n",
      "          Train Loss 0.2733, Train Acc 0.847\n",
      "          Val Loss 0.9928, Val Acc 0.5863\n",
      "\n",
      "[35/300]\n",
      "          Train Loss 0.3309, Train Acc 0.8361\n",
      "          Val Loss 0.9814, Val Acc 0.6224\n",
      "\n",
      "[36/300]\n",
      "          Train Loss 0.3309, Train Acc 0.8497\n",
      "          Val Loss 0.8097, Val Acc 0.6746\n",
      "\n",
      "[37/300]\n",
      "          Train Loss 0.2589, Train Acc 0.8479\n",
      "          Val Loss 0.7939, Val Acc 0.6746\n",
      "\n",
      "[38/300]\n",
      "          Train Loss 0.2949, Train Acc 0.8325\n",
      "          Val Loss 0.915, Val Acc 0.6305\n",
      "\n",
      "[39/300]\n",
      "          Train Loss 0.2517, Train Acc 0.8457\n",
      "          Val Loss 1.0466, Val Acc 0.5983\n",
      "\n",
      "[40/300]\n",
      "          Train Loss 0.2661, Train Acc 0.8407\n",
      "          Val Loss 1.0896, Val Acc 0.6144\n",
      "\n",
      "[41/300]\n",
      "          Train Loss 0.2374, Train Acc 0.8457\n",
      "          Val Loss 0.8144, Val Acc 0.6666\n",
      "\n",
      "[42/300]\n",
      "          Train Loss 0.2733, Train Acc 0.8542\n",
      "          Val Loss 0.9846, Val Acc 0.5983\n",
      "\n",
      "[43/300]\n",
      "          Train Loss 0.2158, Train Acc 0.8678\n",
      "          Val Loss 1.0309, Val Acc 0.6064\n",
      "\n",
      "[44/300]\n",
      "          Train Loss 0.3165, Train Acc 0.857\n",
      "          Val Loss 1.1738, Val Acc 0.5582\n",
      "\n",
      "[45/300]\n",
      "          Train Loss 0.223, Train Acc 0.8683\n",
      "          Val Loss 0.9346, Val Acc 0.6465\n",
      "\n",
      "[46/300]\n",
      "          Train Loss 0.2589, Train Acc 0.8619\n",
      "          Val Loss 0.8534, Val Acc 0.6626\n",
      "\n",
      "[47/300]\n",
      "          Train Loss 0.2374, Train Acc 0.8624\n",
      "          Val Loss 1.0428, Val Acc 0.6184\n",
      "\n",
      "[48/300]\n",
      "          Train Loss 0.2302, Train Acc 0.8656\n",
      "          Val Loss 0.9018, Val Acc 0.6345\n",
      "\n",
      "[49/300]\n",
      "          Train Loss 0.2374, Train Acc 0.8556\n",
      "          Val Loss 1.102, Val Acc 0.5863\n",
      "\n",
      "[50/300]\n",
      "          Train Loss 0.2589, Train Acc 0.8479\n",
      "          Val Loss 1.0254, Val Acc 0.6265\n",
      "\n",
      "[51/300]\n",
      "          Train Loss 0.2733, Train Acc 0.8597\n",
      "          Val Loss 0.9002, Val Acc 0.6586\n",
      "\n",
      "[52/300]\n",
      "          Train Loss 0.2733, Train Acc 0.8601\n",
      "          Val Loss 0.985, Val Acc 0.6265\n",
      "\n",
      "[53/300]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m gradients \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss_value, model\u001b[38;5;241m.\u001b[39mtrainable_weights)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Update model weights\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgradients\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_weights\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m train_epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mround(loss_value\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     46\u001b[0m train_epoch_accuracy\u001b[38;5;241m.\u001b[39mupdate_state(targets, predictions)\n",
      "File \u001b[0;32m~/anaconda3/envs/ai-env/lib/python3.9/site-packages/keras/optimizers/optimizer_experimental/optimizer.py:1140\u001b[0m, in \u001b[0;36mOptimizer.apply_gradients\u001b[0;34m(self, grads_and_vars, name, skip_gradients_aggregation, **kwargs)\u001b[0m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_gradients_aggregation \u001b[38;5;129;01mand\u001b[39;00m experimental_aggregate_gradients:\n\u001b[1;32m   1139\u001b[0m     grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maggregate_gradients(grads_and_vars)\n\u001b[0;32m-> 1140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads_and_vars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ai-env/lib/python3.9/site-packages/keras/optimizers/optimizer_experimental/optimizer.py:634\u001b[0m, in \u001b[0;36m_BaseOptimizer.apply_gradients\u001b[0;34m(self, grads_and_vars, name)\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_weight_decay(trainable_variables)\n\u001b[1;32m    633\u001b[0m grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(grads, trainable_variables))\n\u001b[0;32m--> 634\u001b[0m iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_apply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads_and_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;66;03m# Apply variable constraints after applying gradients.\u001b[39;00m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m variable \u001b[38;5;129;01min\u001b[39;00m trainable_variables:\n",
      "File \u001b[0;32m~/anaconda3/envs/ai-env/lib/python3.9/site-packages/keras/optimizers/optimizer_experimental/optimizer.py:1166\u001b[0m, in \u001b[0;36mOptimizer._internal_apply_gradients\u001b[0;34m(self, grads_and_vars)\u001b[0m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_internal_apply_gradients\u001b[39m(\u001b[38;5;28mself\u001b[39m, grads_and_vars):\n\u001b[0;32m-> 1166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__internal__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaybe_merge_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1167\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distributed_apply_gradients_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1168\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distribution_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads_and_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1170\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ai-env/lib/python3.9/site-packages/tensorflow/python/distribute/merge_call_interim.py:51\u001b[0m, in \u001b[0;36mmaybe_merge_call\u001b[0;34m(fn, strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m\"\"\"Maybe invoke `fn` via `merge_call` which may or may not be fulfilled.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03mThe caller of this utility function requests to invoke `fn` via `merge_call`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03m  The return value of the `fn` call.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m strategy_supports_no_merge_call():\n\u001b[0;32m---> 51\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m distribution_strategy_context\u001b[38;5;241m.\u001b[39mget_replica_context()\u001b[38;5;241m.\u001b[39mmerge_call(\n\u001b[1;32m     54\u001b[0m       fn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/ai-env/lib/python3.9/site-packages/keras/optimizers/optimizer_experimental/optimizer.py:1216\u001b[0m, in \u001b[0;36mOptimizer._distributed_apply_gradients_fn\u001b[0;34m(self, distribution, grads_and_vars, **kwargs)\u001b[0m\n\u001b[1;32m   1213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_step(grad, var)\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m grad, var \u001b[38;5;129;01min\u001b[39;00m grads_and_vars:\n\u001b[0;32m-> 1216\u001b[0m     \u001b[43mdistribution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapply_grad_to_update_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_ema:\n\u001b[1;32m   1221\u001b[0m     _, var_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mgrads_and_vars)\n",
      "File \u001b[0;32m~/anaconda3/envs/ai-env/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2637\u001b[0m, in \u001b[0;36mStrategyExtendedV2.update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2634\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[1;32m   2635\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   2636\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m-> 2637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2638\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2639\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_replica_ctx_update(\n\u001b[1;32m   2640\u001b[0m       var, fn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs, group\u001b[38;5;241m=\u001b[39mgroup)\n",
      "File \u001b[0;32m~/anaconda3/envs/ai-env/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3710\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   3707\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update\u001b[39m(\u001b[38;5;28mself\u001b[39m, var, fn, args, kwargs, group):\n\u001b[1;32m   3708\u001b[0m   \u001b[38;5;66;03m# The implementations of _update() and _update_non_slot() are identical\u001b[39;00m\n\u001b[1;32m   3709\u001b[0m   \u001b[38;5;66;03m# except _update() passes `var` as the first argument to `fn()`.\u001b[39;00m\n\u001b[0;32m-> 3710\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_non_slot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ai-env/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3716\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update_non_slot\u001b[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[1;32m   3712\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_non_slot\u001b[39m(\u001b[38;5;28mself\u001b[39m, colocate_with, fn, args, kwargs, should_group):\n\u001b[1;32m   3713\u001b[0m   \u001b[38;5;66;03m# TODO(josh11b): Figure out what we should be passing to UpdateContext()\u001b[39;00m\n\u001b[1;32m   3714\u001b[0m   \u001b[38;5;66;03m# once that value is used for something.\u001b[39;00m\n\u001b[1;32m   3715\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m UpdateContext(colocate_with):\n\u001b[0;32m-> 3716\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3717\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_group:\n\u001b[1;32m   3718\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/ai-env/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:595\u001b[0m, in \u001b[0;36mcall_with_unspecified_conversion_status.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    594\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mControlStatusCtx(status\u001b[38;5;241m=\u001b[39mag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mUNSPECIFIED):\n\u001b[0;32m--> 595\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ai-env/lib/python3.9/site-packages/keras/optimizers/optimizer_experimental/optimizer.py:1213\u001b[0m, in \u001b[0;36mOptimizer._distributed_apply_gradients_fn.<locals>.apply_grad_to_update_var\u001b[0;34m(var, grad)\u001b[0m\n\u001b[1;32m   1211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_step_xla(grad, var, \u001b[38;5;28mid\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_var_key(var)))\n\u001b[1;32m   1212\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ai-env/lib/python3.9/site-packages/keras/optimizers/optimizer_experimental/optimizer.py:224\u001b[0m, in \u001b[0;36m_BaseOptimizer._update_step\u001b[0;34m(self, gradient, variable)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_var_key(variable) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_dict:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe optimizer cannot recognize variable \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvariable\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis usually means you are trying to call the optimizer to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.keras.optimizers.legacy.\u001b[39m\u001b[38;5;132;01m{self.__class__.__name__}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    223\u001b[0m     )\n\u001b[0;32m--> 224\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariable\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ai-env/lib/python3.9/site-packages/keras/optimizers/optimizer_experimental/adam.py:162\u001b[0m, in \u001b[0;36mAdam.update_step\u001b[0;34m(self, gradient, variable)\u001b[0m\n\u001b[1;32m    160\u001b[0m beta_2_power \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    161\u001b[0m lr \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_rate, variable\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m--> 162\u001b[0m local_step \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterations\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m, variable\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    163\u001b[0m beta_1_power \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mpow(tf\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta_1, variable\u001b[38;5;241m.\u001b[39mdtype), local_step)\n\u001b[1;32m    164\u001b[0m beta_2_power \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mpow(tf\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta_2, variable\u001b[38;5;241m.\u001b[39mdtype), local_step)\n",
      "File \u001b[0;32m~/anaconda3/envs/ai-env/lib/python3.9/site-packages/tensorflow/python/ops/variables.py:1090\u001b[0m, in \u001b[0;36mVariable._OverloadOperator.<locals>._run_op\u001b[0;34m(a, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_op\u001b[39m(a, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1089\u001b[0m   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m-> 1090\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor_oper\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ai-env/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/ai-env/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:1407\u001b[0m, in \u001b[0;36m_OverrideBinaryOperatorHelper.<locals>.binary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1403\u001b[0m   \u001b[38;5;66;03m# force_same_dtype=False to preserve existing TF behavior\u001b[39;00m\n\u001b[1;32m   1404\u001b[0m   \u001b[38;5;66;03m# TODO(b/178860388): Figure out why binary_op_wrapper and\u001b[39;00m\n\u001b[1;32m   1405\u001b[0m   \u001b[38;5;66;03m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[39;00m\n\u001b[1;32m   1406\u001b[0m   x, y \u001b[38;5;241m=\u001b[39m maybe_promote_tensors(x, y)\n\u001b[0;32m-> 1407\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1408\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1409\u001b[0m   \u001b[38;5;66;03m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[39;00m\n\u001b[1;32m   1410\u001b[0m   \u001b[38;5;66;03m# object that can implement the operator with knowledge of itself\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1413\u001b[0m   \u001b[38;5;66;03m# original error from the LHS, because it may be more\u001b[39;00m\n\u001b[1;32m   1414\u001b[0m   \u001b[38;5;66;03m# informative.\u001b[39;00m\n\u001b[1;32m   1415\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mtype\u001b[39m(y), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__r\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m op_name):\n",
      "File \u001b[0;32m~/anaconda3/envs/ai-env/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/ai-env/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1178\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/ai-env/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:1757\u001b[0m, in \u001b[0;36m_add_dispatch\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1755\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m gen_math_ops\u001b[38;5;241m.\u001b[39madd(x, y, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m   1756\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_math_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ai-env/lib/python3.9/site-packages/tensorflow/python/ops/gen_math_ops.py:458\u001b[0m, in \u001b[0;36madd_v2\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_v2\u001b[39m(x, y, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    445\u001b[0m   \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Returns x + y element-wise.\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \n\u001b[1;32m    447\u001b[0m \u001b[38;5;124;03m  *NOTE*: `Add` supports broadcasting. `AddN` does not. More about broadcasting\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;124;03m    A `Tensor`. Has the same type as `x`.\u001b[39;00m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 458\u001b[0m   _ctx \u001b[38;5;241m=\u001b[39m \u001b[43m_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m _context\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m    459\u001b[0m   tld \u001b[38;5;241m=\u001b[39m _ctx\u001b[38;5;241m.\u001b[39m_thread_local_data\n\u001b[1;32m    460\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 300\n",
    "\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "train_steps = len(train_generator)\n",
    "val_steps = len(val_generator)\n",
    "\n",
    "\n",
    "def apply_gaussian_noise(image_batch):\n",
    "    noisy_batch = np.empty_like(image_batch)\n",
    "    for i, image in enumerate(image_batch):\n",
    "        noisy_batch[i] = random_noise(image, mode='gaussian', var=0.01)\n",
    "    return noisy_batch\n",
    "\n",
    "# Custom training loop\n",
    "for epoch in range(epochs):\n",
    "    print(f\"[{epoch + 1}/{epochs}]\")\n",
    "    train_epoch_loss = 0.0 \n",
    "    train_epoch_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()  \n",
    "    val_epoch_loss = 0.0  \n",
    "    val_epoch_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()  \n",
    "    \n",
    "    train_done_percent = train_steps / 20\n",
    "    for step in range(train_steps):\n",
    "        # Perform training steps and compute training loss and accuracy as before\n",
    "        inputs, targets = train_generator.next()\n",
    "        #noisy_inputs = apply_gaussian_noise(inputs)\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Perform data augmentation\n",
    "            #noisy_inputs = ...  # Apply noise or other augmentations to inputs\n",
    "\n",
    "            # Forward pass\n",
    "            predictions = model(inputs)\n",
    "            loss_value = loss_fn(targets, predictions)\n",
    "            \n",
    "\n",
    "        # Compute gradients\n",
    "        gradients = tape.gradient(loss_value, model.trainable_weights)\n",
    "\n",
    "        # Update model weights\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "        \n",
    "        \n",
    "        train_epoch_loss += np.round(loss_value.numpy())\n",
    "        train_epoch_accuracy.update_state(targets, predictions)\n",
    "        \n",
    "#         if int(train_done_percent) == step and not(step == (train_steps-1)):\n",
    "#             print(f\"{int((step/train_steps)*100)}%\", end=\" \")\n",
    "#             train_done_percent += (train_steps / 20)\n",
    "#         elif step == (train_steps-1):\n",
    "#             print(\"100%\")\n",
    "#             print(\"\")\n",
    "            \n",
    "        \n",
    "#     for step in range(train_steps):\n",
    "#         train_inputs, train_targets = train_generator.next()\n",
    "\n",
    "#         # Forward pass on validation data\n",
    "#         train_predictions = model(train_inputs)\n",
    "#         #train_loss_value = loss_fn(train_targets, train_predictions)\n",
    "\n",
    "#         # Accumulate validation loss\n",
    "#         train_epoch_loss += loss_fn(train_targets, train_predictions)\n",
    "\n",
    "#         train_epoch_accuracy.update_state(train_targets, train_predictions)\n",
    "    \n",
    "    for step in range(val_steps):\n",
    "        val_inputs, val_targets = val_generator.next()\n",
    "\n",
    "        # Forward pass on validation data\n",
    "        val_predictions = model(val_inputs)\n",
    "\n",
    "        # Accumulate validation loss\n",
    "        val_epoch_loss += loss_fn(val_targets, val_predictions)\n",
    "\n",
    "        val_epoch_accuracy.update_state(val_targets, val_predictions)\n",
    "\n",
    "    # Calculate average training and validation loss for the epoch\n",
    "    average_train_loss = train_epoch_loss / train_steps\n",
    "    average_val_loss = val_epoch_loss / val_steps\n",
    "\n",
    "    # Calculate training and validation accuracy for the epoch\n",
    "    train_accuracy = train_epoch_accuracy.result()\n",
    "    val_accuracy = val_epoch_accuracy.result()\n",
    "    \n",
    "\n",
    "    float_precision=6 #make sure values are bewteen 0 to 1\n",
    "    \n",
    "    # Print total loss and accuracy for the epoch\n",
    "    print(f\"          Train Loss {float(str(average_train_loss)[:float_precision])}, Train Acc {float(str(train_accuracy.numpy())[:float_precision])}\")\n",
    "    print(f\"          Val Loss {float(str(average_val_loss.numpy())[:float_precision])}, Val Acc {float(str(val_accuracy.numpy())[:float_precision])}\")\n",
    "    print(\"\")\n",
    "    # Reset the metrics for the next epoch\n",
    "    train_epoch_accuracy.reset_states()\n",
    "    val_epoch_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248d5a91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b0a100",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc69a8c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1223"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(str(average_train_loss)[:float_precision])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "aecc6a3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3438"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(str(train_accuracy.numpy())[:float_precision])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "316abd64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e456ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a2cca97b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16,)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14896c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1dda4f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3170 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# def preprocessing_function(image):\n",
    "#     return image.astype(np.uint8)\n",
    "\n",
    "\n",
    "datagen=ImageDataGenerator(#rescale=1./255,\n",
    "                                #  rotation_range=10,\n",
    "                                #  width_shift_range=0.1,\n",
    "                                #  height_shift_range=0.1,\n",
    "                                #  horizontal_flip=True,\n",
    "                                #  fill_mode='nearest'\n",
    "                          #  preprocessing_function=preprocessing_function,\n",
    "                                 )\n",
    "generator=datagen.flow_from_directory(train_data_dir,\n",
    "                                      target_size=IMAGE_SHAPE,\n",
    "                                      batch_size=1,\n",
    "#                                       color_mode=\"grayscale\",\n",
    "                                      class_mode='sparse')\n",
    "\n",
    "def representative_data_gen():\n",
    "    i = 0\n",
    "    for image_batch, labels_batch in generator:\n",
    "        # print(image_batch.shape)\n",
    "        # print(image_batch)\n",
    "        i = i+1\n",
    "        if i > 100:\n",
    "              break;\n",
    "        # print(image_batch.shape)  \n",
    "        yield [image_batch]\n",
    "\n",
    "# next(representative_data_gen())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebae582d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e9a42d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting the optimization flags..\n",
      "\n",
      "Converting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 35). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpbhi9h33i/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpbhi9h33i/assets\n",
      "/home/glarus/anaconda3/envs/ai-env/lib/python3.9/site-packages/tensorflow/lite/python/convert.py:765: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
      "2023-06-30 12:01:19.979335: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2023-06-30 12:01:19.979376: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2023-06-30 12:01:19.979532: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmpbhi9h33i\n",
      "2023-06-30 12:01:19.998362: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-06-30 12:01:19.998396: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /tmp/tmpbhi9h33i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Conversion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: UINT8, output_inference_type: FLOAT32\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "print('\\nSetting the optimization flags..')\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.float32\n",
    "print('\\nConverting...')\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "open(\"30june2_80_60_rgb_1900params_custom.tflite\", \"wb\").write(tflite_model)\n",
    "\n",
    "#open(\"mnv3_small_alpha_0.05.tflite\", \"wb\").write(tflite_model)\n",
    "\n",
    "print(\"Done Conversion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5974e8dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7749548f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7cf69b34",
   "metadata": {},
   "source": [
    "# inference on tflite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b9859706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_scale =  1.0  input_zero_point =  0\n",
      "output_scale =  0.0  output_zero_point =  0\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=\"21_june_1100_params_300_epoch_97acc_.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "\n",
    "input_scale, input_zero_point = input_details[0]['quantization']\n",
    "print(\"input_scale = \", input_scale, \" input_zero_point = \", input_zero_point)\n",
    "\n",
    "output_details = interpreter.get_output_details()\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "output_scale, output_zero_point = output_details[0]['quantization']\n",
    "print(\"output_scale = \", output_scale, \" output_zero_point = \", output_zero_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "fc74682b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00390625 0.9609375  0.03515625]]\n",
      "[[0. 0. 0.]]\n",
      "All classes =  ['angle', 'no_desired_object', 'pipe']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "img_float = next(representative_data_gen())\n",
    "img_int8 = np.clip(np.round(x / input_scale) + input_zero_point, -128, 127).astype(np.uint8)\n",
    "\n",
    "\n",
    "#interpreter = tf.lite.Interpreter(model_path=\"/content/person_detect_model_data.tflite\")\n",
    "#interpreter.allocate_tensors()\n",
    "\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "interpreter.set_tensor(input_details[0]['index'], img_int8) #p is input image 1, 96, 96, 1\n",
    "\n",
    "interpreter.invoke()\n",
    "\n",
    "output_details = interpreter.get_output_details()\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "output_data_float = np.array(output_data, dtype=np.float32)\n",
    "for i in range(output_data.shape[0]):\n",
    "    for j in range(output_data.shape[1]):\n",
    "        output_data_float[i][j] = (output_data[i][j] - output_zero_point) * output_scale  \n",
    "output_data_postprocessed = np.argmax(output_data_float, axis=-1)\n",
    "\n",
    "print(output_data)\n",
    "print(output_data_float)\n",
    "\n",
    "print(\"All classes = \", list(train_generator.class_indices.keys()))\n",
    "plt.imshow(img_float[0].squeeze())\n",
    "plt.title(list(train_generator.class_indices.keys())[np.argmax(output_data, axis=-1)[0]])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64f584f",
   "metadata": {},
   "source": [
    "# Visualize prediction using tf and tflite on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e2fb5eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    }
   ],
   "source": [
    "import glob, cv2\n",
    "\n",
    "\n",
    "pred_folder_path = \"/home/glarus/HOOK_PROJECT/DATA_COLLECTION_HOOK/single_img_data3_exracted/all\"\n",
    "\n",
    "trained_model_path = \"27june.tflite\"\n",
    "\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path=trained_model_path)\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "for img_path in glob.glob((pred_folder_path+\"/*\")):\n",
    "    \n",
    "    img = cv2.imread(img_path)\n",
    "    #print(\"before \", img)\n",
    "    inp_img = cv2.resize(img, (160, 120))[:,:,::-1]\n",
    "    #print(\"after \", inp_img)\n",
    "    inp_img = np.expand_dims(inp_img, axis = 0)\n",
    "    #inp_img = \n",
    "\n",
    "    #tf inference\n",
    "    \n",
    "    pred = model.predict(inp_img)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #tflite inference\n",
    "    interpreter.set_tensor(input_details[0]['index'], inp_img)\n",
    "    \n",
    "    interpreter.invoke()\n",
    "    \n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    \n",
    "    black_img = np.zeros_like(img)\n",
    "    \n",
    "    cv2.putText(black_img, \"TF \" + class_names[np.argmax(pred)], (5, 20),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "    cv2.putText(black_img, \"TF \" + str(np.round(np.max(pred)*100))+\" %\", (5, 40),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "    \n",
    "    cv2.putText(black_img, \"TFL \" + class_names[np.argmax(output_data)], (5, 60),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "    cv2.putText(black_img, \"TFL \" + str(np.round(np.max(output_data)*100))+\" %\", (5, 80),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "    \n",
    "    img_and_pred = np.concatenate((img, black_img), axis=1)\n",
    "    \n",
    "    cv2.imshow('Live',img_and_pred)\n",
    "    key = cv2.waitKey(0) & 0xFF\n",
    "    if  key == ord('Q') or key == ord('q'):\n",
    "        break\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e38aa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107399fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29719c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5a4ea8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e43cb538",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_adjust_brightness(image, target_mean):\n",
    "\n",
    "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "\n",
    "    l_channel, a_channel, b_channel = cv2.split(lab_image)\n",
    "\n",
    "\n",
    "    l_mean = np.mean(l_channel)\n",
    "\n",
    "\n",
    "    target_mean = target_mean # default 150  # Adjust this value as desired\n",
    "\n",
    "    diff = target_mean - l_mean\n",
    "\n",
    "\n",
    "\n",
    "    adjusted_l_channel = np.clip(l_channel + diff, 0, 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "    adjusted_lab_image = cv2.merge((adjusted_l_channel, a_channel, b_channel))\n",
    "\n",
    "    adjusted_bgr_image = cv2.cvtColor(adjusted_lab_image, cv2.COLOR_LAB2BGR)    \n",
    "    \n",
    "    return adjusted_bgr_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ab6e6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    }
   ],
   "source": [
    "import glob, cv2\n",
    "\n",
    "\n",
    "pred_folder_path = \"/home/glarus/HOOK_PROJECT/DATA_COLLECTION_HOOK/single_img_data3_exracted4/all\"\n",
    "\n",
    "trained_model_path = \"30june_80_60_rgb_1900params_custom.tflite\"\n",
    "\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path=trained_model_path)\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "for img_path in sorted(glob.glob((pred_folder_path+\"/*\"))):\n",
    "    \n",
    "    img = cv2.imread(img_path)\n",
    "    #print(\"before \", img)\n",
    "    inp_img = img[:, 0:320, :]\n",
    "    inp_img = cv2.resize(inp_img, (80, 60))\n",
    "    inp_img = auto_adjust_brightness(inp_img, 140)\n",
    "    \n",
    "\n",
    "    \n",
    "    inp_img = inp_img[:,:,::-1] #convert to rgb from bgr\n",
    "    #print(\"after \", inp_img)\n",
    "\n",
    "#     cv2.imshow('Live1',inp_img)\n",
    "#     key = cv2.waitKey(0) & 0xFF\n",
    "#     if  key == ord('Q') or key == ord('q'):\n",
    "#         break\n",
    "#     else:\n",
    "#         pass    \n",
    "    \n",
    "    inp_img = np.expand_dims(inp_img, axis = 0)\n",
    "    #inp_img = \n",
    "\n",
    "    #tf inference\n",
    "    \n",
    "    pred = model.predict(inp_img)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #tflite inference\n",
    "    interpreter.set_tensor(input_details[0]['index'], inp_img)\n",
    "    \n",
    "    interpreter.invoke()\n",
    "    \n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    \n",
    "    black_img = np.zeros_like(img[:,0:320,:])\n",
    "    \n",
    "    cv2.putText(black_img, \"TF \" + class_names[np.argmax(pred)], (5, 20),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "    cv2.putText(black_img, \"TF \" + str(np.round(np.max(pred)*100))+\" %\", (5, 40),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "    \n",
    "    cv2.putText(black_img, \"TFL \" + class_names[np.argmax(output_data)], (5, 60),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "    cv2.putText(black_img, \"TFL \" + str(np.round(np.max(output_data)*100))+\" %\", (5, 80),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "    \n",
    "    img_and_pred = np.concatenate((img, black_img), axis=1)\n",
    "    \n",
    "    cv2.imshow('Live',img_and_pred)\n",
    "    key = cv2.waitKey(0) & 0xFF\n",
    "    if  key == ord('Q') or key == ord('q'):\n",
    "        break\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "af2f43a1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c3ca3166",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, cv2, time\n",
    "\n",
    "\n",
    "pred_folder_path = \"/home/glarus/HOOK_PROJECT/TRAIN_MODEL_IPYNB_FILE/pred_vis1688011306.8640738\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path=trained_model_path)\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "for img_path in sorted(glob.glob((pred_folder_path+\"/*\"))):\n",
    "    \n",
    "    img = cv2.imread(img_path)\n",
    "    #print(\"before \", img)\n",
    "    inp_img = img[:, 0:320, :]\n",
    "    inp_img = cv2.resize(inp_img, (160, 120))\n",
    "    cv2.imwrite(\"/home/glarus/HOOK_PROJECT/DATA_COLLECTION_HOOK/single_img_data3_exracted4/all/\"+img_path.split(\"/\")[-1], inp_img)\n",
    "\n",
    "#     cv2.imshow('Live1',inp_img)\n",
    "#     key = cv2.waitKey(0) & 0xFF\n",
    "#     if  key == ord('Q') or key == ord('q'):\n",
    "#         break\n",
    "#     elif key == ord('A') or key == ord('a'):\n",
    "#         cv2.imwrite(\"/home/glarus/HOOK_PROJECT/DATA_COLLECTION_HOOK/single_img_data3_exracted/angle/\"+str(time.time()).replace(\".\", \"\")+\".jpg\", inp_img)\n",
    "#     elif key == ord('N') or key == ord('n'):\n",
    "#         cv2.imwrite(\"/home/glarus/HOOK_PROJECT/DATA_COLLECTION_HOOK/single_img_data3_exracted/none/\"+str(time.time()).replace(\".\", \"\")+\".jpg\", inp_img) \n",
    "#     elif key == ord('P') or key == ord('p'):\n",
    "#         cv2.imwrite(\"/home/glarus/HOOK_PROJECT/DATA_COLLECTION_HOOK/single_img_data3_exracted/pipe/\"+str(time.time()).replace(\".\", \"\")+\".jpg\", inp_img)\n",
    "#     else:\n",
    "#         pass \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "dcce0b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_folder_path = \"/home/glarus/HOOK_PROJECT/TRAIN_MODEL_IPYNB_FILE/pred_vis1687931320.024529\"\n",
    "x = sorted(glob.glob((pred_folder_path+\"/*\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c7cebb7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1687931327907829.jpg'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].split(\"/\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "37ff5172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.12.0'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tflite_runtime.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "db4637d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 120, 160, 3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a79924fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 160, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "black_img = np.zeros_like(img)\n",
    "black_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dba98bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 320, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1 = np.zeros((120, 160, 3))\n",
    "arr2 = np.ones((120, 160, 3))\n",
    "\n",
    "res = np.concatenate((arr1, arr2), axis=1)\n",
    "\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c97cf75a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 160, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43892458",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260c334c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "e89e82f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!xxd -i ./person_detect_model_data.tflite > person_detect_model_data.cpp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820208f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "24d5d8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text replaced\n"
     ]
    }
   ],
   "source": [
    "\n",
    "search_text1 = \"unsigned char __person_detect_model_data_tflite[]\"\n",
    "\n",
    "\n",
    "replace_text1 = str('#include \"person_detect_model_data.h\" \\n\\\n",
    "#ifdef __has_attribute \\n\\\n",
    "#define HAVE_ATTRIBUTE(x) __has_attribute(x) \\n\\\n",
    "#else \\n\\\n",
    "#define HAVE_ATTRIBUTE(x) 0 \\n\\\n",
    "#endif \\n\\\n",
    "#if HAVE_ATTRIBUTE(aligned) || (defined(__GNUC__) && !defined(__clang__)) \\n\\\n",
    "#define DATA_ALIGN_ATTRIBUTE __attribute__((aligned(4))) \\n\\\n",
    "#else \\n\\\n",
    "#define DATA_ALIGN_ATTRIBUTE \\n\\\n",
    "#endif \\n\\\n",
    "const unsigned char g_person_detect_model_data[] DATA_ALIGN_ATTRIBUTE')\n",
    "\n",
    "\n",
    "search_text2 = \"unsigned int __person_detect_model_data_tflite_len\"\n",
    "\n",
    "replace_text2 = \"const int g_person_detect_model_data_len\"\n",
    "\n",
    "with open(r'person_detect_model_data.cpp', 'r') as file:\n",
    "\n",
    "    data = file.read()\n",
    "\n",
    "    data = data.replace(search_text1, replace_text1)\n",
    "    data = data.replace(search_text2, replace_text2)\n",
    "  # data = data.replace(search_text2, replace_text2)\n",
    "\n",
    "with open(r'person_detect_model_data.cpp', 'w') as file:\n",
    "    file.write(data)\n",
    "    file.close()\n",
    "\n",
    "\n",
    "\n",
    "print(\"Text replaced\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7342a46f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
